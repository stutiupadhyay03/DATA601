{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a82a2ea",
   "metadata": {},
   "source": [
    "#### Name : Stuti Upadhyay\n",
    "#### Campus ID : XT81177\n",
    "#### Instructor : Chalachew Jemberie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1423cc4d",
   "metadata": {},
   "source": [
    "This excercise is based on the  Datasets and the Noteboo that I shared during the class\n",
    "============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974aaa3",
   "metadata": {},
   "source": [
    "Based on the titles and sections identified in the notebook \"Medical Solution Take Home Exercise - DS Pricing,\" the notebook appears to be focused on developing a dynamic pricing model in the Chicago taxi market. \n",
    "\n",
    "-It covers data importation, preliminary data understanding, data cleaning (including handling duplicates, missing values, inconsistencies, and outliers), visualizations, time series analysis, and modeling approaches for dynamic pricing. \n",
    "\n",
    "Here are some  questions based on these sections, mainly focused on the Exploratory Data Analysis (EDA) work:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82345b6d",
   "metadata": {},
   "source": [
    "I) Thoughtful and Anlyses thinking Quesions\n",
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f2232",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Understanding the Data**: Given the initial data understanding steps outlined, can you identify any potential biases in the dataset that might affect the reliability of the dynamic pricing model? Consider the types of data collected and any significant data missingness.\n",
    "\n",
    "2. **Handling Missing/Null Values**: The notebook outlines strategies for handling missing values. What are the implications of the chosen strategy on the dataset's integrity and the resulting pricing model? How might different imputation strategies affect the model's predictions?\n",
    "\n",
    "3. **Converting Trip Times**: The conversion of trip start and end times to datetime format is crucial for time series analysis. Discuss how this conversion facilitates the analysis of taxi fares over different times of the day and its impact on identifying peak demand periods for dynamic pricing.\n",
    "\n",
    "4. **Handling Outliers**: How does the approach to handling outliers in the dataset influence the analysis of trip distance and fare? Consider how extreme values could affect the understanding of typical fares and distances within the Chicago taxi market.\n",
    "\n",
    "5. **Visualizations - Relationship Between Trip Distance and Fare Over Time**: Analyze the approach used to understand the relationship between trip distance and fare over time. How does this analysis contribute to the development of a dynamic pricing model, and what insights can be derived about fare sensitivity?\n",
    "\n",
    "6. **Heatmaps for Ride Intensity**: How do the heatmaps used to understand ride intensity over geographical areas within Chicago inform the dynamic pricing strategy? Discuss the implications of ride intensity patterns on pricing elasticity and demand forecasting.\n",
    "\n",
    "7. **Time Series Analysis - Payment Types**: Reflect on the analysis of payment types for rides over time. How could the variability in payment types influence dynamic pricing strategies and customer behavior?\n",
    "\n",
    "8. **Average Total Fare Collected Over Days of the Week**: How does understanding the average total fare collected over different days of the week contribute to the dynamic pricing model? Discuss how day-of-week trends might be used to adjust pricing strategies to maximize revenue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8704d6f",
   "metadata": {},
   "source": [
    "   II)Pandas Capabilies Coding Quesions\n",
    "   ======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898cbdc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Pandas Question:\n",
    "\n",
    "**Analyzing Weekday vs. Weekend Demand and Pricing Strategy**\n",
    "\n",
    "Given the taxi rides dataset, analyze the difference in demand (number of rides) and average fare between weekdays and weekends. Then, based on the average distance traveled, suggest a dynamic pricing multiplier for weekends to optimize revenue.\n",
    "\n",
    "**Requirements:**\n",
    "- Use Pandas to filter the dataset into two parts: one for weekdays and another for weekends.\n",
    "- Calculate the average number of rides and the average fare for both weekdays and weekends.\n",
    "- Group the data based on the average distance traveled into short, medium, and long trips for each category (weekday and weekend) and calculate the average fare for each group.\n",
    "- Suggest a dynamic pricing multiplier for weekends, assuming that the demand is higher during weekends.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "The following code snippet is designed to start the analysis, with key parts left for you to complete:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the taxi rides data\n",
    "# and it has columns 'start_time', 'fare', and 'trip_distance'\n",
    "\n",
    "# Convert 'start_time' to datetime\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "\n",
    "# Add a column to differentiate between weekdays and weekends\n",
    "df['day_type'] = df['start_time'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "\n",
    "# Calculate average number of rides and average fare for weekdays and weekends\n",
    "avg_metrics = df.groupby('day_type')['fare'].agg(['count', 'mean']).rename(columns={'count': 'avg_rides', 'mean': 'avg_fare'})\n",
    "print(avg_metrics)\n",
    "\n",
    "# Group data based on the average distance traveled (short: <= 5 km, medium: > 5 km and <= 15 km, long: > 15 km)\n",
    "# and calculate the average fare for each group within weekdays and weekends\n",
    "# TODO: The student will complete this part\n",
    "\n",
    "# Suggest dynamic pricing multipliers based on the analysis\n",
    "# TODO: The student will complete this part\n",
    "```\n",
    "\n",
    "###  Tasks:\n",
    "\n",
    "1. **Complete the missing code** to group the data based on trip distance into 'short', 'medium', and 'long' trips and calculate the average fare for each group within weekdays and weekends.\n",
    "2. **Analyze the results** to identify trends in average fare across different trip lengths and day types.\n",
    "3. **Propose dynamic pricing multipliers** for weekend rides, based on the demand and average fare differences observed. Justify your suggested multipliers with the analysis conducted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100f7047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avg_rides   avg_fare\n",
      "day_type                      \n",
      "Weekday        2603  11.480638\n",
      "Weekend         318  15.967767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1991222309.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1991222309.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['day_type'] = df['trip_start_timestamp'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Taxi-trips_Babylon-Express-Inc.csv')\n",
    "df = data.dropna()\n",
    "\n",
    "# Convert 'trip_start_timestamp' to datetime\n",
    "df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "\n",
    "# Add a column to differentiate between weekdays and weekends\n",
    "df['day_type'] = df['trip_start_timestamp'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "\n",
    "# Calculate average number of rides and average fare for weekdays and weekends\n",
    "avg_metrics = df.groupby('day_type')['fare'].agg(['count', 'mean']).rename(columns={'count': 'avg_rides', 'mean': 'avg_fare'})\n",
    "print(avg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d275584c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>day_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb8694eca7debf530d306fd391135696cac9e55c</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2020-02-26 18:45:00+00:00</td>\n",
       "      <td>2020-02-26 19:15:00.000000 UTC</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703106e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>POINT (-87.6318639497 41.8920421365)</td>\n",
       "      <td>41.934762</td>\n",
       "      <td>-87.639854</td>\n",
       "      <td>POINT (-87.6398538587 41.9347624564)</td>\n",
       "      <td>1/1/2012 0:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9db244a8a13c748ea882b0e8925e9eb7a12468f</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2020-02-11 17:00:00+00:00</td>\n",
       "      <td>2020-02-11 18:00:00.000000 UTC</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "      <td>POINT (-87.6378442095 41.8932163595)</td>\n",
       "      <td>41.785999</td>\n",
       "      <td>-87.750934</td>\n",
       "      <td>POINT (-87.7509342894 41.785998518)</td>\n",
       "      <td>1/1/2012 1:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aae822b7350507c89e8b57c69d9b0ce4f1369f5f</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-13 19:30:00+00:00</td>\n",
       "      <td>2019-03-13 19:30:00.000000 UTC</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703106e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Cash</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.905858</td>\n",
       "      <td>-87.630865</td>\n",
       "      <td>POINT (-87.6308650266 41.9058577688)</td>\n",
       "      <td>41.934650</td>\n",
       "      <td>-87.634648</td>\n",
       "      <td>POINT (-87.6346478774 41.9346504482)</td>\n",
       "      <td>1/1/2012 8:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8467be4179181f63f00d5747299e313ea1c7ae9b</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-14 21:30:00+00:00</td>\n",
       "      <td>2019-03-14 21:30:00.000000 UTC</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703124e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>POINT (-87.6318639497 41.8920421365)</td>\n",
       "      <td>41.892658</td>\n",
       "      <td>-87.652534</td>\n",
       "      <td>POINT (-87.6525344838 41.8926581076)</td>\n",
       "      <td>1/1/2012 9:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22a2c3c526195702ef4ffebacb4c94f8e926a952</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-14 19:45:00+00:00</td>\n",
       "      <td>2019-03-14 20:00:00.000000 UTC</td>\n",
       "      <td>840.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703122e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "      <td>POINT (-87.6378442095 41.8932163595)</td>\n",
       "      <td>41.921273</td>\n",
       "      <td>-87.685082</td>\n",
       "      <td>POINT (-87.6850821101 41.92127310530001)</td>\n",
       "      <td>1/1/2012 12:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>15f32e296a86c57ea36b79539327c1e1f6ab6c3d</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-02-08 18:00:00+00:00</td>\n",
       "      <td>2019-02-08 18:15:00.000000 UTC</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.880994</td>\n",
       "      <td>-87.632746</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>POINT (-87.6499072264 41.9049353016)</td>\n",
       "      <td>7/12/2012 5:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>2cd0aa824b1af8e74a83667130e6b7443dc81558</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-02-25 12:45:00+00:00</td>\n",
       "      <td>2019-02-25 13:00:00.000000 UTC</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "      <td>POINT (-87.6318639497 41.8920421365)</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>POINT (-87.6499072264 41.9049353016)</td>\n",
       "      <td>7/12/2012 6:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>fc9cf7b092bc1ab176588dc5d93bccce11cf7a2b</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-16 12:00:00+00:00</td>\n",
       "      <td>2019-03-16 12:15:00.000000 UTC</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.892508</td>\n",
       "      <td>-87.626215</td>\n",
       "      <td>POINT (-87.6262149064 41.8925077809)</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>POINT (-87.6499072264 41.9049353016)</td>\n",
       "      <td>7/12/2012 7:00</td>\n",
       "      <td>Weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>68da213fee4b7c482c241414e544443bcc7d6a90</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-05 13:45:00+00:00</td>\n",
       "      <td>2019-03-05 14:00:00.000000 UTC</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "      <td>POINT (-87.6378442095 41.8932163595)</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>POINT (-87.6499072264 41.9049353016)</td>\n",
       "      <td>7/12/2012 8:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>de8ebe4882d2779b94869c3a4609d2ceb4a94d7a</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2020-02-17 14:45:00+00:00</td>\n",
       "      <td>2020-02-17 15:30:00.000000 UTC</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>6574 - Babylon Express Inc.</td>\n",
       "      <td>41.979071</td>\n",
       "      <td>-87.903040</td>\n",
       "      <td>POINT (-87.9030396611 41.9790708201)</td>\n",
       "      <td>41.904935</td>\n",
       "      <td>-87.649907</td>\n",
       "      <td>POINT (-87.6499072264 41.9049353016)</td>\n",
       "      <td>7/12/2012 9:00</td>\n",
       "      <td>Weekday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2921 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    unique_key  \\\n",
       "0     fb8694eca7debf530d306fd391135696cac9e55c   \n",
       "1     f9db244a8a13c748ea882b0e8925e9eb7a12468f   \n",
       "8     aae822b7350507c89e8b57c69d9b0ce4f1369f5f   \n",
       "9     8467be4179181f63f00d5747299e313ea1c7ae9b   \n",
       "12    22a2c3c526195702ef4ffebacb4c94f8e926a952   \n",
       "...                                        ...   \n",
       "4637  15f32e296a86c57ea36b79539327c1e1f6ab6c3d   \n",
       "4638  2cd0aa824b1af8e74a83667130e6b7443dc81558   \n",
       "4639  fc9cf7b092bc1ab176588dc5d93bccce11cf7a2b   \n",
       "4640  68da213fee4b7c482c241414e544443bcc7d6a90   \n",
       "4641  de8ebe4882d2779b94869c3a4609d2ceb4a94d7a   \n",
       "\n",
       "                                                taxi_id  \\\n",
       "0     ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "1     ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "8     ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "9     ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "12    ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "...                                                 ...   \n",
       "4637  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "4638  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "4639  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "4640  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "4641  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "\n",
       "          trip_start_timestamp              trip_end_timestamp  trip_seconds  \\\n",
       "0    2020-02-26 18:45:00+00:00  2020-02-26 19:15:00.000000 UTC        1140.0   \n",
       "1    2020-02-11 17:00:00+00:00  2020-02-11 18:00:00.000000 UTC        3180.0   \n",
       "8    2019-03-13 19:30:00+00:00  2019-03-13 19:30:00.000000 UTC         540.0   \n",
       "9    2019-03-14 21:30:00+00:00  2019-03-14 21:30:00.000000 UTC         420.0   \n",
       "12   2019-03-14 19:45:00+00:00  2019-03-14 20:00:00.000000 UTC         840.0   \n",
       "...                        ...                             ...           ...   \n",
       "4637 2019-02-08 18:00:00+00:00  2019-02-08 18:15:00.000000 UTC        1440.0   \n",
       "4638 2019-02-25 12:45:00+00:00  2019-02-25 13:00:00.000000 UTC         600.0   \n",
       "4639 2019-03-16 12:00:00+00:00  2019-03-16 12:15:00.000000 UTC        1080.0   \n",
       "4640 2019-03-05 13:45:00+00:00  2019-03-05 14:00:00.000000 UTC         420.0   \n",
       "4641 2020-02-17 14:45:00+00:00  2020-02-17 15:30:00.000000 UTC        2640.0   \n",
       "\n",
       "      trip_miles  pickup_census_tract  dropoff_census_tract  \\\n",
       "0            4.5         1.703108e+10          1.703106e+10   \n",
       "1           11.3         1.703108e+10          1.703198e+10   \n",
       "8            2.3         1.703108e+10          1.703106e+10   \n",
       "9            1.4         1.703108e+10          1.703124e+10   \n",
       "12           4.1         1.703108e+10          1.703122e+10   \n",
       "...          ...                  ...                   ...   \n",
       "4637         2.6         1.703184e+10          1.703184e+10   \n",
       "4638         2.3         1.703108e+10          1.703184e+10   \n",
       "4639         3.1         1.703108e+10          1.703184e+10   \n",
       "4640         1.7         1.703108e+10          1.703184e+10   \n",
       "4641        14.5         1.703198e+10          1.703184e+10   \n",
       "\n",
       "      pickup_community_area  dropoff_community_area  ...  payment_type  \\\n",
       "0                       8.0                     6.0  ...   Credit Card   \n",
       "1                       8.0                    56.0  ...   Credit Card   \n",
       "8                       8.0                     6.0  ...          Cash   \n",
       "9                       8.0                    24.0  ...   Credit Card   \n",
       "12                      8.0                    22.0  ...   Credit Card   \n",
       "...                     ...                     ...  ...           ...   \n",
       "4637                   32.0                     8.0  ...   Credit Card   \n",
       "4638                    8.0                     8.0  ...   Credit Card   \n",
       "4639                    8.0                     8.0  ...   Credit Card   \n",
       "4640                    8.0                     8.0  ...   Credit Card   \n",
       "4641                   76.0                     8.0  ...   Credit Card   \n",
       "\n",
       "                          company  pickup_latitude  pickup_longitude  \\\n",
       "0     6574 - Babylon Express Inc.        41.892042        -87.631864   \n",
       "1     6574 - Babylon Express Inc.        41.893216        -87.637844   \n",
       "8     6574 - Babylon Express Inc.        41.905858        -87.630865   \n",
       "9     6574 - Babylon Express Inc.        41.892042        -87.631864   \n",
       "12    6574 - Babylon Express Inc.        41.893216        -87.637844   \n",
       "...                           ...              ...               ...   \n",
       "4637  6574 - Babylon Express Inc.        41.880994        -87.632746   \n",
       "4638  6574 - Babylon Express Inc.        41.892042        -87.631864   \n",
       "4639  6574 - Babylon Express Inc.        41.892508        -87.626215   \n",
       "4640  6574 - Babylon Express Inc.        41.893216        -87.637844   \n",
       "4641  6574 - Babylon Express Inc.        41.979071        -87.903040   \n",
       "\n",
       "                           pickup_location dropoff_latitude dropoff_longitude  \\\n",
       "0     POINT (-87.6318639497 41.8920421365)        41.934762        -87.639854   \n",
       "1     POINT (-87.6378442095 41.8932163595)        41.785999        -87.750934   \n",
       "8     POINT (-87.6308650266 41.9058577688)        41.934650        -87.634648   \n",
       "9     POINT (-87.6318639497 41.8920421365)        41.892658        -87.652534   \n",
       "12    POINT (-87.6378442095 41.8932163595)        41.921273        -87.685082   \n",
       "...                                    ...              ...               ...   \n",
       "4637  POINT (-87.6327464887 41.8809944707)        41.904935        -87.649907   \n",
       "4638  POINT (-87.6318639497 41.8920421365)        41.904935        -87.649907   \n",
       "4639  POINT (-87.6262149064 41.8925077809)        41.904935        -87.649907   \n",
       "4640  POINT (-87.6378442095 41.8932163595)        41.904935        -87.649907   \n",
       "4641  POINT (-87.9030396611 41.9790708201)        41.904935        -87.649907   \n",
       "\n",
       "                              dropoff_location       Date/Time day_type  \n",
       "0         POINT (-87.6398538587 41.9347624564)   1/1/2012 0:00  Weekday  \n",
       "1          POINT (-87.7509342894 41.785998518)   1/1/2012 1:00  Weekday  \n",
       "8         POINT (-87.6346478774 41.9346504482)   1/1/2012 8:00  Weekday  \n",
       "9         POINT (-87.6525344838 41.8926581076)   1/1/2012 9:00  Weekday  \n",
       "12    POINT (-87.6850821101 41.92127310530001)  1/1/2012 12:00  Weekday  \n",
       "...                                        ...             ...      ...  \n",
       "4637      POINT (-87.6499072264 41.9049353016)  7/12/2012 5:00  Weekday  \n",
       "4638      POINT (-87.6499072264 41.9049353016)  7/12/2012 6:00  Weekday  \n",
       "4639      POINT (-87.6499072264 41.9049353016)  7/12/2012 7:00  Weekend  \n",
       "4640      POINT (-87.6499072264 41.9049353016)  7/12/2012 8:00  Weekday  \n",
       "4641      POINT (-87.6499072264 41.9049353016)  7/12/2012 9:00  Weekday  \n",
       "\n",
       "[2921 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55c99b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  day_type distance_category       fare\n",
      "0  Weekday              Long  44.865385\n",
      "1  Weekday            Medium  32.215686\n",
      "2  Weekday             Short   7.232155\n",
      "3  Weekend              Long  44.768657\n",
      "4  Weekend            Medium  31.916667\n",
      "5  Weekend             Short   7.993952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/3249409904.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['distance_category'] = df['trip_miles'].apply(categorize_distance)\n"
     ]
    }
   ],
   "source": [
    "# Define function to categorize trip distance\n",
    "def categorize_distance(distance):\n",
    "    if distance <= 5:\n",
    "        return 'Short'\n",
    "    elif distance <= 15:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Long'\n",
    "\n",
    "# Apply the categorization function to create a new column 'distance_category'\n",
    "df['distance_category'] = df['trip_miles'].apply(categorize_distance)\n",
    "\n",
    "# Group data by 'day_type' and 'distance_category', then calculate average fare\n",
    "avg_fare_by_distance = df.groupby(['day_type', 'distance_category'])['fare'].mean().reset_index()\n",
    "print(avg_fare_by_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9577db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Pricing Multiplier for Weekends: 1.0043415345334739\n"
     ]
    }
   ],
   "source": [
    "# Calculate dynamic pricing multipliers based on average fare differences\n",
    "weekday_avg_fare = avg_fare_by_distance[avg_fare_by_distance['day_type'] == 'Weekday']['fare'].mean()\n",
    "weekend_avg_fare = avg_fare_by_distance[avg_fare_by_distance['day_type'] == 'Weekend']['fare'].mean()\n",
    "\n",
    "# Assuming a 10% increase in fare during weekends\n",
    "multiplier = weekend_avg_fare / weekday_avg_fare\n",
    "\n",
    "print(\"Dynamic Pricing Multiplier for Weekends:\", multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02db2b7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  Weekday vs. Weekend Ride Duration Analysis\n",
    "\n",
    "**Objective:** Compare the average ride duration between weekdays and weekends. Investigate whether ride durations are significantly longer or shorter on weekends compared to weekdays.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# Calculate the ride duration\n",
    "df['ride_duration'] = (df['end_time'] - df['start_time']).dt.total_seconds() / 60\n",
    "\n",
    "# TODO: Group by 'day_type' and calculate the average 'ride_duration' for weekdays and weekends\n",
    "```\n",
    "\n",
    "###  Impact of Weather on Taxi Demand\n",
    "\n",
    "**Objective:** Assuming you have an additional dataset `weather_df` with daily weather conditions (e.g., 'Rain', 'Sunny', 'Snow'), merge this dataset with your taxi rides dataset and analyze how weather conditions affect the average number of rides.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# Merge the taxi rides dataset with the weather dataset\n",
    "# Assume weather_df has columns 'date' and 'weather_condition', and df has 'start_time'\n",
    "\n",
    "# TODO: Perform the merge operation and analyze the impact of weather conditions on the number of rides\n",
    "```\n",
    "\n",
    "###  Analyzing Fare Efficiency by Trip Distance\n",
    "\n",
    "**Objective:** Calculate the fare efficiency as fare per kilometer for each ride. Identify which trip distance range (short, medium, long) has the highest average fare efficiency.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# Calculate fare efficiency\n",
    "df['fare_efficiency'] = df['fare'] / df['trip_distance']\n",
    "\n",
    "# TODO: Categorize trips into short, medium, and long, then calculate average fare efficiency for each category\n",
    "```\n",
    "\n",
    "###  Time of Day Analysis\n",
    "\n",
    "**Objective:** Examine how taxi fares vary by time of day (morning, afternoon, evening, night). Determine which time period has the highest average fare and hypothesize why.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# TODO: Create a 'time_of_day' column based on 'start_time', then group by this column to calculate average fare\n",
    "```\n",
    "\n",
    "###  Seasonal Demand Variation\n",
    "\n",
    "**Objective:** Explore how taxi demand varies by season. Assume you can derive the season from the `start_time` column (e.g., December-February: Winter). \n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# TODO: Derive a 'season' column from 'start_time', then analyze the average number of rides per season\n",
    "```\n",
    "\n",
    "### Distribution of Payment Types\n",
    "\n",
    "**Objective:** Investigate the distribution of payment types across different times of the day. Identify any trends or patterns.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# TODO: Group data by 'time_of_day' and 'payment_type' to see the distribution of payment types\n",
    "```\n",
    "\n",
    "### Relationship Between Distance and Speed\n",
    "\n",
    "**Objective:** Calculate the average speed (km/h) for each ride. Explore the relationship between trip distance and speed. Identify any trends or outliers.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# Calculate speed\n",
    "df['speed_km_per_hr'] = df['trip_distance'] / (df['ride_duration'] / 60)\n",
    "\n",
    "# TODO: Analyze the relationship between 'trip_distance' and 'speed_km_per_hr'\n",
    "```\n",
    "\n",
    "### Analyzing Ride Popularity by Pickup Location\n",
    "\n",
    "**Objective:** Determine the most and least popular pickup locations. Explore how this popularity affects average fares.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# TODO: Group data by 'pickup_location' to find the most and least popular locations and their average fares\n",
    "```\n",
    "\n",
    "###  Effect of Trip Start Times on Fares\n",
    "\n",
    "**Objective:** Analyze how the start time of trips (broken down into hourly intervals) influences the fare. Identify peak hours with the highest fares.\n",
    "\n",
    "**Code Challenge:**\n",
    "```python\n",
    "# TODO: Create an 'hour_of_day' column from 'start_time', then analyze how average fare varies by hour\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccb5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_type\n",
      "Weekday    12.787169\n",
      "Weekend    14.528302\n",
      "Name: ride_duration, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1866415606.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1866415606.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trip_end_timestamp'] = pd.to_datetime(df['trip_end_timestamp'])\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1866415606.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ride_duration'] = (df['trip_end_timestamp'] - df['trip_start_timestamp']).dt.total_seconds() / 60\n"
     ]
    }
   ],
   "source": [
    "### Weekday vs. Weekend Ride Duration Analysis\n",
    "\n",
    "# Convert columns to datetime type\n",
    "df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "df['trip_end_timestamp'] = pd.to_datetime(df['trip_end_timestamp'])\n",
    "\n",
    "# Calculate the ride duration\n",
    "df['ride_duration'] = (df['trip_end_timestamp'] - df['trip_start_timestamp']).dt.total_seconds() / 60\n",
    "\n",
    "# Group by 'day_type' and calculate the average 'ride_duration' for weekdays and weekends\n",
    "avg_duration_by_day = df.groupby('day_type')['ride_duration'].mean()\n",
    "print(avg_duration_by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18701997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Temp_C</th>\n",
       "      <th>Dew Point Temp_C</th>\n",
       "      <th>Rel Hum_%</th>\n",
       "      <th>Wind Speed_km/h</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Press_kPa</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2012 0:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2012 1:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2012 2:00</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.26</td>\n",
       "      <td>Freezing Drizzle,Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2012 3:00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.27</td>\n",
       "      <td>Freezing Drizzle,Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2012 4:00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>101.23</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date/Time  Temp_C  Dew Point Temp_C  Rel Hum_%  Wind Speed_km/h  \\\n",
       "0  1/1/2012 0:00    -1.8              -3.9         86                4   \n",
       "1  1/1/2012 1:00    -1.8              -3.7         87                4   \n",
       "2  1/1/2012 2:00    -1.8              -3.4         89                7   \n",
       "3  1/1/2012 3:00    -1.5              -3.2         88                6   \n",
       "4  1/1/2012 4:00    -1.5              -3.3         88                7   \n",
       "\n",
       "   Visibility_km  Press_kPa               Weather  \n",
       "0            8.0     101.24                   Fog  \n",
       "1            8.0     101.24                   Fog  \n",
       "2            4.0     101.26  Freezing Drizzle,Fog  \n",
       "3            4.0     101.27  Freezing Drizzle,Fog  \n",
       "4            4.8     101.23                   Fog  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Impact of Weather on Taxi Demand\n",
    "\n",
    "weather_df = pd.read_csv('Weather Data.csv')\n",
    "weather_df.head(5)\n",
    "\n",
    "# Merge the taxi rides dataset with the weather dataset\n",
    "# Assume weather_df has columns 'date' and 'weather_condition', and df has 'start_time'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9355e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>...</th>\n",
       "      <th>day_type</th>\n",
       "      <th>distance_category</th>\n",
       "      <th>ride_duration</th>\n",
       "      <th>Temp_C</th>\n",
       "      <th>Dew Point Temp_C</th>\n",
       "      <th>Rel Hum_%</th>\n",
       "      <th>Wind Speed_km/h</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Press_kPa</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb8694eca7debf530d306fd391135696cac9e55c</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2020-02-26 18:45:00+00:00</td>\n",
       "      <td>2020-02-26 19:15:00+00:00</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703106e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Short</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9db244a8a13c748ea882b0e8925e9eb7a12468f</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2020-02-11 17:00:00+00:00</td>\n",
       "      <td>2020-02-11 18:00:00+00:00</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Medium</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.24</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aae822b7350507c89e8b57c69d9b0ce4f1369f5f</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-13 19:30:00+00:00</td>\n",
       "      <td>2019-03-13 19:30:00+00:00</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703106e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.23</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8467be4179181f63f00d5747299e313ea1c7ae9b</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-14 21:30:00+00:00</td>\n",
       "      <td>2019-03-14 21:30:00+00:00</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703124e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Short</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22a2c3c526195702ef4ffebacb4c94f8e926a952</td>\n",
       "      <td>ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...</td>\n",
       "      <td>2019-03-14 19:45:00+00:00</td>\n",
       "      <td>2019-03-14 20:00:00+00:00</td>\n",
       "      <td>840.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703122e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Short</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>100.79</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 unique_key  \\\n",
       "0  fb8694eca7debf530d306fd391135696cac9e55c   \n",
       "1  f9db244a8a13c748ea882b0e8925e9eb7a12468f   \n",
       "2  aae822b7350507c89e8b57c69d9b0ce4f1369f5f   \n",
       "3  8467be4179181f63f00d5747299e313ea1c7ae9b   \n",
       "4  22a2c3c526195702ef4ffebacb4c94f8e926a952   \n",
       "\n",
       "                                             taxi_id  \\\n",
       "0  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "1  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "2  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "3  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "4  ba48aac1be874e3212623beb83b4538c5567a8676f2cf3...   \n",
       "\n",
       "       trip_start_timestamp        trip_end_timestamp  trip_seconds  \\\n",
       "0 2020-02-26 18:45:00+00:00 2020-02-26 19:15:00+00:00        1140.0   \n",
       "1 2020-02-11 17:00:00+00:00 2020-02-11 18:00:00+00:00        3180.0   \n",
       "2 2019-03-13 19:30:00+00:00 2019-03-13 19:30:00+00:00         540.0   \n",
       "3 2019-03-14 21:30:00+00:00 2019-03-14 21:30:00+00:00         420.0   \n",
       "4 2019-03-14 19:45:00+00:00 2019-03-14 20:00:00+00:00         840.0   \n",
       "\n",
       "   trip_miles  pickup_census_tract  dropoff_census_tract  \\\n",
       "0         4.5         1.703108e+10          1.703106e+10   \n",
       "1        11.3         1.703108e+10          1.703198e+10   \n",
       "2         2.3         1.703108e+10          1.703106e+10   \n",
       "3         1.4         1.703108e+10          1.703124e+10   \n",
       "4         4.1         1.703108e+10          1.703122e+10   \n",
       "\n",
       "   pickup_community_area  dropoff_community_area  ...  day_type  \\\n",
       "0                    8.0                     6.0  ...   Weekday   \n",
       "1                    8.0                    56.0  ...   Weekday   \n",
       "2                    8.0                     6.0  ...   Weekday   \n",
       "3                    8.0                    24.0  ...   Weekday   \n",
       "4                    8.0                    22.0  ...   Weekday   \n",
       "\n",
       "   distance_category  ride_duration  Temp_C  Dew Point Temp_C Rel Hum_%  \\\n",
       "0              Short           30.0    -1.8              -3.9        86   \n",
       "1             Medium           60.0    -1.8              -3.7        87   \n",
       "2              Short            0.0    -1.4              -3.6        85   \n",
       "3              Short            0.0    -1.3              -3.1        88   \n",
       "4              Short           15.0    -0.2              -2.0        88   \n",
       "\n",
       "  Wind Speed_km/h  Visibility_km  Press_kPa Weather  \n",
       "0               4            8.0     101.24     Fog  \n",
       "1               4            8.0     101.24     Fog  \n",
       "2               9            8.0     101.23     Fog  \n",
       "3              15            4.0     101.20     Fog  \n",
       "4               9            4.8     100.79     Fog  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df, weather_df, on='Date/Time')\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bdf0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [total_rides, avg_fare]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df, weather_df, left_on=df['trip_start_timestamp'].dt.date, right_on=weather_df['Date/Time'])\n",
    "\n",
    "# Group by 'weather' and analyze the impact on the number of rides\n",
    "rides_by_weather = merged_df.groupby('Weather')['fare'].agg(['count', 'mean']).rename(columns={'count': 'total_rides', 'mean': 'avg_fare'})\n",
    "print(rides_by_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd2d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_category\n",
      "Long      2.524270\n",
      "Medium    2.880833\n",
      "Short          NaN\n",
      "Name: fare_efficiency, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/2809062368.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['fare_efficiency'] = df['fare'] / df['trip_miles']\n"
     ]
    }
   ],
   "source": [
    "### Analyzing Fare Efficiency by Trip Distance\n",
    "\n",
    "# Calculate fare efficiency\n",
    "df['fare_efficiency'] = df['fare'] / df['trip_miles']\n",
    "\n",
    "# Group by 'distance_category' and calculate average fare efficiency\n",
    "avg_fare_efficiency = df.groupby('distance_category')['fare_efficiency'].mean()\n",
    "print(avg_fare_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d407620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_of_day\n",
      "Afternoon    12.875954\n",
      "Evening      10.689459\n",
      "Morning      12.373149\n",
      "Name: fare, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1221165678.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time_of_day'] = df['trip_start_timestamp'].dt.hour.apply(lambda x: 'Morning' if 5 <= x < 12 else 'Afternoon' if 12 <= x < 17 else 'Evening' if 17 <= x < 22 else 'Night')\n"
     ]
    }
   ],
   "source": [
    "### Time of Day Analysis\n",
    "\n",
    "# Create a 'time_of_day' column based on 'start_time'\n",
    "df['time_of_day'] = df['trip_start_timestamp'].dt.hour.apply(lambda x: 'Morning' if 5 <= x < 12 else 'Afternoon' if 12 <= x < 17 else 'Evening' if 17 <= x < 22 else 'Night')\n",
    "\n",
    "# Group by 'time_of_day' and calculate average fare\n",
    "avg_fare_by_time = df.groupby('time_of_day')['fare'].mean()\n",
    "print(avg_fare_by_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1578cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        total_rides   avg_fare\n",
      "season                        \n",
      "Fall            946  16.480180\n",
      "Spring          491  10.319246\n",
      "Summer          106  13.129717\n",
      "Winter         1378   9.370900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/967021016.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['season'] = df['trip_start_timestamp'].dt.month.apply(lambda x: 'Winter' if x in [12, 1, 2] else 'Spring' if x in [3, 4, 5] else 'Summer' if x in [6, 7, 8] else 'Fall')\n"
     ]
    }
   ],
   "source": [
    "### Seasonal Demand Variation\n",
    "\n",
    "# Derive a 'season' column from 'start_time'\n",
    "df['season'] = df['trip_start_timestamp'].dt.month.apply(lambda x: 'Winter' if x in [12, 1, 2] else 'Spring' if x in [3, 4, 5] else 'Summer' if x in [6, 7, 8] else 'Fall')\n",
    "\n",
    "# Analyze the average number of rides per season\n",
    "avg_rides_by_season = df.groupby('season')['fare'].agg(['count', 'mean']).rename(columns={'count': 'total_rides', 'mean': 'avg_fare'})\n",
    "print(avg_rides_by_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359bd149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment_type  Cash  Credit Card  Dispute  Unknown\n",
      "time_of_day                                      \n",
      "Afternoon      479          699        1        0\n",
      "Evening        436          616        1        0\n",
      "Morning        241          445        0        3\n"
     ]
    }
   ],
   "source": [
    "### Distribution of Payment Types\n",
    "\n",
    "# Group data by 'time_of_day' and 'payment_type' to see the distribution of payment types\n",
    "payment_distribution = df.groupby(['time_of_day', 'payment_type']).size().unstack(fill_value=0)\n",
    "print(payment_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2a7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_miles\n",
      "0.0      0.000000\n",
      "0.1           NaN\n",
      "0.2           NaN\n",
      "0.3           NaN\n",
      "0.4           NaN\n",
      "          ...    \n",
      "21.0    28.000000\n",
      "21.1    24.616667\n",
      "21.2    28.266667\n",
      "21.5    28.666667\n",
      "34.1    45.466667\n",
      "Name: speed_km_per_hr, Length: 132, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/3186508882.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['speed_km_per_hr'] = df['trip_miles'] / (df['ride_duration'] / 60)\n"
     ]
    }
   ],
   "source": [
    "### Relationship Between Distance and Speed\n",
    "\n",
    "# Calculate speed\n",
    "df['speed_km_per_hr'] = df['trip_miles'] / (df['ride_duration'] / 60)\n",
    "\n",
    "# Analyze the relationship between 'trip_distance' and 'speed_km_per_hr'\n",
    "distance_speed_relationship = df.groupby('trip_miles')['speed_km_per_hr'].mean()\n",
    "print(distance_speed_relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27135b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          total_rides   avg_fare\n",
      "pickup_location                                                 \n",
      "POINT (-87.6129454143 41.8919715078)                3   7.000000\n",
      "POINT (-87.6173580061 41.859349715)                13  12.980769\n",
      "POINT (-87.6188683546 41.8909220259)               17   7.382353\n",
      "POINT (-87.6197106717 41.8950334495)               10   6.900000\n",
      "POINT (-87.6207628651 41.8983317935)               15   7.683333\n",
      "POINT (-87.6209929134 41.8849871918)               47   8.468085\n",
      "POINT (-87.6219716519 41.8774061234)               22   8.227273\n",
      "POINT (-87.6221729369 41.8706073724)               20  12.225000\n",
      "POINT (-87.6241352979 41.8492467545)                5   9.250000\n",
      "POINT (-87.6261455896 41.9027880476)                5   6.250000\n",
      "POINT (-87.6262105324 41.8991556134)               64   9.773438\n",
      "POINT (-87.6262149064 41.8925077809)              167   9.852695\n",
      "POINT (-87.6266589003 41.9075200747)                2  14.375000\n",
      "POINT (-87.6266589003 41.90752007470001)            2   9.375000\n",
      "POINT (-87.6288741572 41.8920726347)              247   8.608097\n",
      "POINT (-87.6291051864 41.9002212967)                2   8.750000\n",
      "POINT (-87.6308650266 41.9058577688)                8   7.281250\n",
      "POINT (-87.630963601 41.9094956686)                 5   7.650000\n",
      "POINT (-87.6317173661 41.9146162864)                4  10.625000\n",
      "POINT (-87.6318639497 41.8920421365)              769   8.257802\n",
      "POINT (-87.6321092196 41.9002656868)               15   6.183333\n",
      "POINT (-87.6327464887 41.8809944707)              480   8.491562\n",
      "POINT (-87.6341560931 41.922082541)                 2   8.500000\n",
      "POINT (-87.6357600901 41.9074919303)                1   8.250000\n",
      "POINT (-87.6378442095 41.8932163595)              591   7.705415\n",
      "POINT (-87.6384040116 41.9015669095)                1   9.000000\n",
      "POINT (-87.6414915334 41.897983898)                 1   6.250000\n",
      "POINT (-87.642648998 41.8792550844)                38   7.039474\n",
      "POINT (-87.6428084655 41.8853000224)               35   7.154286\n",
      "POINT (-87.6429586652 41.8679024175)                1   4.250000\n",
      "POINT (-87.6499072264 41.9049353016)                2   6.500000\n",
      "POINT (-87.657005027 41.8790669938)                 1   8.500000\n",
      "POINT (-87.6572331997 41.8852813201)                8   6.781250\n",
      "POINT (-87.6813558293 41.8335178865)                5   3.250000\n",
      "POINT (-87.7509342894 41.785998518)                14  35.732143\n",
      "POINT (-87.9030396611 41.9790708201)              299  42.583612\n"
     ]
    }
   ],
   "source": [
    "### Analyzing Ride Popularity by Pickup Location\n",
    "\n",
    "# Group data by 'pickup_location' to find the most and least popular locations and their average fares\n",
    "popular_locations = df.groupby('pickup_location')['fare'].agg(['count', 'mean']).rename(columns={'count': 'total_rides', 'mean': 'avg_fare'})\n",
    "print(popular_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80cfe216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_of_day\n",
      "6     31.916667\n",
      "7     20.078947\n",
      "8      9.631159\n",
      "9     11.836911\n",
      "10    14.163764\n",
      "11    12.104688\n",
      "12    11.058824\n",
      "13    11.998992\n",
      "14    12.383721\n",
      "15    15.162383\n",
      "16    14.177602\n",
      "17    10.380471\n",
      "18    12.386029\n",
      "19     9.991993\n",
      "20     8.478632\n",
      "21     9.000000\n",
      "Name: fare, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/1282014085.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hour_of_day'] = df['trip_start_timestamp'].dt.hour\n"
     ]
    }
   ],
   "source": [
    "### Effect of Trip Start Times on Fares\n",
    "\n",
    "# Create an 'hour_of_day' column from 'start_time'\n",
    "df['hour_of_day'] = df['trip_start_timestamp'].dt.hour\n",
    "\n",
    "# Analyze how average fare varies by hour\n",
    "avg_fare_by_hour = df.groupby('hour_of_day')['fare'].mean()\n",
    "print(avg_fare_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e56bd7",
   "metadata": {},
   "source": [
    "More Challenging Excercise\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1b86e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  Correlation Analysis Between Weather and Fare Efficiency\n",
    "\n",
    "**Objective:** Assuming access to weather data, examine the correlation between different weather conditions and fare efficiency. Investigate whether certain weather conditions lead to higher fare efficiency.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Assume 'weather_condition' is merged into the main dataframe\n",
    "# Calculate 'fare_efficiency' as fare per kilometer\n",
    "# Explore the correlation between 'weather_condition' and 'fare_efficiency'\n",
    "```\n",
    "\n",
    "###  Predicting Peak Demand Zones Using Geospatial Data\n",
    "\n",
    "**Objective:** Use pickup location coordinates to identify potential hotspots for taxi demand during different times of the day. Apply clustering techniques if possible, or aggregate rides by geographical areas to highlight these zones.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Assume 'pickup_latitude' and 'pickup_longitude' are available\n",
    "# Aggregate or cluster rides to identify high-demand zones during morning, afternoon, and night\n",
    "```\n",
    "\n",
    "### Analysis of Trip Durations Over Months\n",
    "\n",
    "**Objective:** Investigate how trip durations vary across different months. Determine if there are any seasonal patterns that affect how long trips take.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Calculate 'ride_duration' in minutes\n",
    "# Extract month from 'start_time' and analyze average 'ride_duration' by month\n",
    "```\n",
    "\n",
    "###  Exploring the Impact of Special Events on Taxi Usage\n",
    "\n",
    "**Objective:** Given a list of dates for special events in the city, examine the impact of these events on taxi demand and fare rates.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Assume a list of special event dates is available\n",
    "# Analyze the number of rides and average fares on these dates compared to other days\n",
    "```\n",
    "\n",
    "### Weekend vs. Weekday Trip Distance Analysis\n",
    "\n",
    "**Objective:** Compare the average trip distance on weekends vs. weekdays. Explore the hypothesis that weekend trips are longer due to leisure activities.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Group data by 'day_type' and calculate average 'trip_distance' for weekdays and weekends\n",
    "```\n",
    "\n",
    "###  Analyzing Driver Efficiency\n",
    "\n",
    "**Objective:** Assuming driver ID data is available, analyze which drivers have the highest fare efficiency and identify any patterns in their trips (time of day, day of week, etc.).\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Group data by 'driver_id' and calculate their average 'fare_efficiency'\n",
    "# Explore patterns in the top performing drivers' trip data\n",
    "```\n",
    "\n",
    "### Fare Predictions Based on External Factors\n",
    "\n",
    "**Objective:** Explore how external factors (weather, special events, day of week) might influence fare predictions. Utilize linear regression or another suitable method for this analysis.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Prepare data for regression analysis, including 'weather_condition', 'is_special_event', and 'day_of_week'\n",
    "# Predict 'fare' based on these external factors\n",
    "```\n",
    "\n",
    "### Analysis of Payment Type Preferences\n",
    "\n",
    "**Objective:** Examine the preference of payment types (cash, credit card, etc.) across different times of the day and in different weather conditions.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Group data by 'payment_type' and then by 'time_of_day' and 'weather_condition'\n",
    "# Analyze the distribution of payment types under different conditions\n",
    "```\n",
    "\n",
    "### Investigating the Impact of Ride Distance on Payment Type Choice\n",
    "\n",
    "**Objective:** Determine if there is a relationship between the distance of the ride and the choice of payment type. Explore the hypothesis that longer trips are more likely to be paid with credit cards.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Categorize trips into distance ranges\n",
    "# Analyze the distribution of 'payment_type' within each range\n",
    "```\n",
    "\n",
    "### Time Series Analysis of Fare Changes\n",
    "\n",
    "**Objective:** Conduct a time series analysis to identify any trends, seasonalities, or patterns in fare changes over time. Utilize decomposition methods to explore these components.\n",
    "\n",
    "**Challenge Setup:**\n",
    "```python\n",
    "# Convert 'start_time' to a datetime index\n",
    "# Use time series decomposition on 'fare' to identify trends and seasonality\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc723a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between weather condition and fare efficiency: nan\n"
     ]
    }
   ],
   "source": [
    "### Correlation Analysis Between Weather and Fare Efficiency\n",
    "\n",
    "# Calculate 'fare_efficiency' as fare per kilometer\n",
    "merged_df['fare_efficiency'] = merged_df['fare'] / merged_df['trip_miles']\n",
    "\n",
    "# Explore the correlation between 'weather_condition' and 'fare_efficiency'\n",
    "correlation = df['fare_efficiency'].corr(merged_df['Weather'])\n",
    "print(\"Correlation between weather condition and fare efficiency:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb415537",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.905858</td>\n",
       "      <td>-87.630865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>41.880994</td>\n",
       "      <td>-87.632746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>41.892042</td>\n",
       "      <td>-87.631864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>41.892508</td>\n",
       "      <td>-87.626215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>41.979071</td>\n",
       "      <td>-87.903040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2921 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_latitude  pickup_longitude\n",
       "0           41.892042        -87.631864\n",
       "1           41.893216        -87.637844\n",
       "8           41.905858        -87.630865\n",
       "9           41.892042        -87.631864\n",
       "12          41.893216        -87.637844\n",
       "...               ...               ...\n",
       "4637        41.880994        -87.632746\n",
       "4638        41.892042        -87.631864\n",
       "4639        41.892508        -87.626215\n",
       "4640        41.893216        -87.637844\n",
       "4641        41.979071        -87.903040\n",
       "\n",
       "[2921 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Predicting Peak Demand Zones Using Geospatial Data\n",
    "\n",
    "# Assume you have access to scikit-learn for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Combine latitude and longitude into a single array\n",
    "coord = df[['pickup_latitude', 'pickup_longitude']]\n",
    "coordinates = coord.dropna(how='all')\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c84396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df: 2921\n",
      "Length of coordinates: 2921\n"
     ]
    }
   ],
   "source": [
    "# Check the lengths of the DataFrames\n",
    "print(\"Length of df:\", len(df))\n",
    "print(\"Length of coordinates:\", len(coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97067d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak demand zones identified: cluster\n",
      "1    2608\n",
      "0     299\n",
      "2      14\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stuti_up_02/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/3357542880.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cluster'] = kmeans.fit_predict(coordinates)\n"
     ]
    }
   ],
   "source": [
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3)  # Adjust number of clusters as needed\n",
    "df['cluster'] = kmeans.fit_predict(coordinates)\n",
    "\n",
    "# Analyze clusters to identify peak demand zones\n",
    "peak_zones = df.groupby('cluster').size().sort_values(ascending=False)\n",
    "print(\"Peak demand zones identified:\", peak_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39fa8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ride duration by month: month\n",
      "1      9.911765\n",
      "2     10.560662\n",
      "3     10.744186\n",
      "4     13.278689\n",
      "8     14.009434\n",
      "9     18.713355\n",
      "10    17.735562\n",
      "11    15.774194\n",
      "12    11.481481\n",
      "Name: ride_duration, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/2559864017.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ride_duration'] = (df['trip_end_timestamp'] - df['trip_start_timestamp']).dt.total_seconds() / 60\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/2559864017.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['month'] = df['trip_start_timestamp'].dt.month\n"
     ]
    }
   ],
   "source": [
    "### Analysis of Trip Durations Over Months\n",
    "\n",
    "# Calculate 'ride_duration' in minutes\n",
    "df['ride_duration'] = (df['trip_end_timestamp'] - df['trip_start_timestamp']).dt.total_seconds() / 60\n",
    "\n",
    "# Extract month from 'start_time'\n",
    "df['month'] = df['trip_start_timestamp'].dt.month\n",
    "\n",
    "# Analyze average 'ride_duration' by month\n",
    "avg_duration_by_month = df.groupby('month')['ride_duration'].mean()\n",
    "print(\"Average ride duration by month:\", avg_duration_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf8e4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on special event dates:                           fare  number_of_rides\n",
      "special_event_dates                            \n",
      "False                11.969137          66660.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/2647393517.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['special_event_dates'] = df['trip_start_timestamp'].dt.date.isin(special_event_dates)\n",
      "/var/folders/s9/w1f1my553ll2rpzvjc_kqfx80000gn/T/ipykernel_85865/2647393517.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['number_of_rides'] = df['dropoff_community_area']\n"
     ]
    }
   ],
   "source": [
    "### Exploring the Impact of Special Events on Taxi Usage\n",
    "\n",
    "# Assume 'special_event_dates' is a list of special event dates but for curent example I'll just use Date/Time\n",
    "# Create a new column indicating whether each date is a special event date\n",
    "special_event_dates = df['Date/Time'].tolist()\n",
    "df['special_event_dates'] = df['trip_start_timestamp'].dt.date.isin(special_event_dates)\n",
    "df['number_of_rides'] = df['dropoff_community_area']\n",
    "\n",
    "# Analyze the number of rides and average fares on special event dates compared to other days\n",
    "special_event_stats = df.groupby('special_event_dates').agg({'fare': 'mean', 'number_of_rides': 'sum'})\n",
    "print(\"Stats on special event dates:\", special_event_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b472da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trip distance by day type: day_type\n",
      "Weekday    2.973070\n",
      "Weekend    4.765094\n",
      "Name: trip_miles, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### Weekend vs. Weekday Trip Distance Analysis\n",
    "\n",
    "# Group data by 'day_type' and calculate average 'trip_distance' for weekdays and weekends\n",
    "avg_trip_distance_by_day = df.groupby('day_type')['trip_miles'].mean()\n",
    "print(\"Average trip distance by day type:\", avg_trip_distance_by_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
