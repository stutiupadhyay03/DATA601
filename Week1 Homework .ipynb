{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e95199",
   "metadata": {},
   "source": [
    "I am Stuti Upadhyay, a 1st Semester MPS Data Science student from India. I did my Bachelors of Technology in Computer Science and Engineering with a Specialization in Artificial Intelligence, Machine Learning and Data Science from GSFC University. Furthermore, I have done several projects in the field of Machine Learning and Data Science, with this coursework I am looking forward to expand my technical horizon and make the correct career growth.I have attached the link to my GitHub profile as well as the Repository. \n",
    "\n",
    "Github Profile: https://github.com/stutiupadhyay03\n",
    "\n",
    "DATA601 Repository Link: https://github.com/stutiupadhyay03/DATA601"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7974dc2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question1: Critical Discussion on Foundations of Data Science\n",
    "\n",
    "#### Objective\n",
    "Engage in a critical discussion about the synergy between Python, Mathematics, and Statistics in Data Science.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c630f8",
   "metadata": {},
   "source": [
    "\n",
    "#### Tasks\n",
    "1. **Integration of Disciplines**:\n",
    "   - Write a 50-100 word essay on how Python, Mathematics, and Statistics integrate in data science. Provide real-world examples.\n",
    "   \n",
    "According to me, every single sector is connected to Mathematics in one way or the other. What makes data science so intricate is its flexibility to blend with other subject matters. One can say that the foundation of Data Science lies between Python, Mathematics, and Statistics although some people do venture towards R when they look forward to advanced problems. One of the prime reasons to use Python in Data Science is the fact that it's simple and consistent along with that the learning curve is low which means that people with no prior background in Python can still learn the language at a relatively faster pace. The world right now is buried within a stockpile of data that is unstructured, unmanaged, and not classified properly, with the help of Mathematics, Statistics, and Python we can create a structure for this data and classify it for proper use. The best example can be the millions of data that enterprises with projects in Generative AI use to infer better results for their users. \n",
    "   \n",
    "\n",
    "2. **Practical vs Theoretical Understanding**:\n",
    "   - Discuss the importance of theoretical knowledge versus practical skills. Which is more crucial, and why?\n",
    "   \n",
    "Theoretical Knowledge can be defined as the basic understanding of the subject matter as well as a deep understanding about what the possible applications can be, wherein Practical Knowledge can be defined as the understanding an individual has about how the theory can be applied in real time scenario and problems. One cannot have enough practical knowledge without basic theoretical understanding, it is very much important to gain both of them simultaneously. \n",
    "\n",
    "3. **Challenges and Strategies**:\n",
    "   - List challenges faced when learning these disciplines together and propose strategies to overcome them.\n",
    "   \n",
    "Usually it's the misconceptions one can gain from having too much theoretical knowledge without understanding proper circumstances that may happen while you actually work on a real-time projects. Best way to tackle it can be making a mock solution and then developig an actual solution step by step.\n",
    "\n",
    "4. **Ethical Considerations**:\n",
    "   - Discuss how a strong foundation in these areas helps address ethical dilemmas in data science.\n",
    "   \n",
    "In all fairness, without basic knowledge about Mathematics or Statistics is almost hard to understand the real life problems we are meant to tackle as data scientist and so it is very important to have a strong background on all three subjects because using unethical mediums such as plagarism or using someone else work should never be a solution to any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d2276",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question2: Create and Share Your GitHub Profile\n",
    "\n",
    "#### Objective\n",
    "Establish a professional GitHub profile to showcase your projects, collaborate with others, and engage with the data science community.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eddcaa",
   "metadata": {},
   "source": [
    "\n",
    "#### Instructions\n",
    "\n",
    "1. **Create Your GitHub Profile**:\n",
    "   - If you don't already have a GitHub account, sign up at [GitHub](https://github.com/).\n",
    "   - Customize your profile:\n",
    "     - Set a professional profile picture.\n",
    "     - Write a clear bio reflecting your interests in data science.\n",
    "     - Add relevant details (e.g., education, skills, contact information).\n",
    "\n",
    "2. **Create a Repository for DATA 601**:\n",
    "   - Create a new repository named `DATA601`.\n",
    "   - Initialize it with a README.md file.\n",
    "   - Describe the purpose of the repository in the README.\n",
    "\n",
    "3. **Share Your Profile and Repository**:\n",
    "   - In a markdown cell in Jupyter, write a brief introduction about yourself.\n",
    "   - Embed links to your GitHub profile and `DATA601` repository.\n",
    "   - Use markdown formatting to organize your content neatly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b3269",
   "metadata": {},
   "source": [
    "### Question3: Python Data Structure Manipulation\n",
    "\n",
    "#### Objective\n",
    "Demonstrate proficiency in using core Python programming concepts to manipulate and process data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304abd7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Task 1: Hypothetical Dataset Challenge\n",
    "\n",
    "1. **Dataset Creation**:\n",
    "   - Create a nested list that represents students' grades in a class. Each element should be a dictionary containing the student's name, ID, and a list of grades.\n",
    "\n",
    "    ```python\n",
    "    students = [\n",
    "        {\"name\": \"Alice\", \"id\": 1, \"grades\": [88, 92, 85]},\n",
    "        {\"name\": \"Bob\", \"id\": 2, \"grades\": [76, 90, 83]},\n",
    "        {\"name\": \"Clara\", \"id\": 3, \"grades\": [91, 85, 89]}\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "2. **Data Manipulation Tasks**:\n",
    "   - Calculate the average grade for each student and add it as a new key-value pair in each dictionary.\n",
    "   - Using list comprehension, create a list of passed students (passing grade is 70).\n",
    "   - Implement a search function that returns a student's record based on the student's ID.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d590ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Dataset Creation:\n",
    "#CREATING THE DATASET WITH STUDENT DATA SUCH AS NAME, ID AND GRADES\n",
    "students = [\n",
    "   {\"name\": \"Stuti\", \"id\": 101, \"grades\": [84, 90, 71]}, \n",
    "   {\"name\": \"Riya\", \"id\": 102, \"grades\": [87, 69, 86]},\n",
    "   {\"name\": \"Vidhi\", \"id\": 103, \"grades\": [98, 88, 89]},\n",
    "   {\"name\": \"Abhisekh\", \"id\": 104, \"grades\": [67, 56, 52]},\n",
    "   {\"name\": \"Sanya\", \"id\": 105, \"grades\": [62, 66, 88]},\n",
    "   {\"name\": \"Abhay\", \"id\": 106, \"grades\": [78, 85, 89]},\n",
    "   {\"name\": \"Rohan\", \"id\": 107, \"grades\": [34, 56, 45]},\n",
    "   {\"name\": \"Tina\", \"id\": 108, \"grades\": [87, 76, 56]},\n",
    "   {\"name\": \"Manan\", \"id\": 109, \"grades\": [32, 46, 75]},\n",
    "   {\"name\": \"Jaynil\", \"id\": 110, \"grades\": [98, 86, 67]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7506bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Stuti', 'id': 101, 'grades': [84, 90, 71]},\n",
       " {'name': 'Riya', 'id': 102, 'grades': [87, 69, 86]},\n",
       " {'name': 'Vidhi', 'id': 103, 'grades': [98, 88, 89]},\n",
       " {'name': 'Abhisekh', 'id': 104, 'grades': [67, 56, 52]},\n",
       " {'name': 'Sanya', 'id': 105, 'grades': [62, 66, 88]},\n",
       " {'name': 'Abhay', 'id': 106, 'grades': [78, 85, 89]},\n",
       " {'name': 'Rohan', 'id': 107, 'grades': [34, 56, 45]},\n",
       " {'name': 'Tina', 'id': 108, 'grades': [87, 76, 56]},\n",
       " {'name': 'Manan', 'id': 109, 'grades': [32, 46, 75]},\n",
       " {'name': 'Jaynil', 'id': 110, 'grades': [98, 86, 67]}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PRINTING THE LIST WE CREATED\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9310ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Data Manipulation Tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c05c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATING THE AVERAGE GRADE FOR EACH STUDENT AND THEN APPENDING IT TO THE LIST\n",
    "#HERE WE WILL CALCULATE THE THE AVERAGE BY DIVIDING THE SUM OF GRADES OF AN INDIVIDUAL WITH THE TOTAL NUMBER OF SCORES MENTIONED IN THE LIST\n",
    "for student in students:\n",
    "    grades = student[\"grades\"]\n",
    "    average_grade = sum(grades) / len(grades)\n",
    "    student[\"average_grade\"] = average_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c029920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Stuti', 'id': 101, 'grades': [84, 90, 71], 'average_grade': 81.66666666666667}\n",
      "{'name': 'Riya', 'id': 102, 'grades': [87, 69, 86], 'average_grade': 80.66666666666667}\n",
      "{'name': 'Vidhi', 'id': 103, 'grades': [98, 88, 89], 'average_grade': 91.66666666666667}\n",
      "{'name': 'Abhisekh', 'id': 104, 'grades': [67, 56, 52], 'average_grade': 58.333333333333336}\n",
      "{'name': 'Sanya', 'id': 105, 'grades': [62, 66, 88], 'average_grade': 72.0}\n",
      "{'name': 'Abhay', 'id': 106, 'grades': [78, 85, 89], 'average_grade': 84.0}\n",
      "{'name': 'Rohan', 'id': 107, 'grades': [34, 56, 45], 'average_grade': 45.0}\n",
      "{'name': 'Tina', 'id': 108, 'grades': [87, 76, 56], 'average_grade': 73.0}\n",
      "{'name': 'Manan', 'id': 109, 'grades': [32, 46, 75], 'average_grade': 51.0}\n",
      "{'name': 'Jaynil', 'id': 110, 'grades': [98, 86, 67], 'average_grade': 83.66666666666667}\n"
     ]
    }
   ],
   "source": [
    "#HERE WE WILL BE PRINTING THE FINAL APPENDED LIST WITH THE AVERAGE GRADES\n",
    "for student in students:\n",
    "    print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92b35517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE WILL PRINT A LIST THAT JUST CONSISTS OF THE STUDENTS THAT HAVE PASSED, HENCE THE STUDENTS WITH AN AVERAGE GRADE OF OVER 70\n",
    "passed_students = [student[\"name\"] for student in students if student[\"average_grade\"] >= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c65d73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Students: ['Stuti', 'Riya', 'Vidhi', 'Sanya', 'Abhay', 'Tina', 'Jaynil']\n"
     ]
    }
   ],
   "source": [
    "#FOLLOWING IS THE LIST OF PASSED STUDENTS\n",
    "print(\"Passed Students:\", passed_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4cd7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW WE WILL CREATE A FUNCTION THAT WILL RETURN THE DETAILS OF A STUDENTS WITH HELP OF THEIR STUDENT ID\n",
    "def search_student_by_id(student_id, student_list):\n",
    "    for student in student_list:\n",
    "        if student[\"id\"] == student_id:\n",
    "            return student\n",
    "    return None  #THIS WRITTEN IN CASE THE ID IS INVALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c7c83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the student ID to search: 105\n"
     ]
    }
   ],
   "source": [
    "#WE WILL TAKE THE INPUT FOR THE ID FROM THE USER\n",
    "student_id_to_search = int(input(\"Enter the student ID to search: \"))\n",
    "found_student = search_student_by_id(student_id_to_search, students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50a7d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student found:\n",
      "{'name': 'Sanya', 'id': 105, 'grades': [62, 66, 88], 'average_grade': 72.0}\n"
     ]
    }
   ],
   "source": [
    "#AND NOW WE WILL PRINT THE FINAL RESULT\n",
    "if found_student:\n",
    "    print(\"Student found:\")\n",
    "    print(found_student)\n",
    "else:\n",
    "    print(f\"No student found with ID {student_id_to_search}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5572d51",
   "metadata": {},
   "source": [
    "#### Task 2: Public Dataset Challenge\n",
    "\n",
    "1. **Dataset Acquisition**:\n",
    "   - Download a public dataset, for example, the Iris dataset from the UCI Machine Learning Repository (use `pandas` or `csv` module to load the data).\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "    column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    iris_data = pd.read_csv(url, names=column_names)\n",
    "    ```\n",
    "\n",
    "2. **Data Manipulation Tasks**:\n",
    "   - Using a loop and conditionals, categorize each iris plant into 'small', 'medium', or 'large' based on sepal length (define your own thresholds).\n",
    "   - Create a new dictionary where each key is a unique class from the dataset, and the value is the average petal width of that class.\n",
    "   - Use list comprehension to create a list of sepal length-to-width ratios for all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8487677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Dataset Acquisition:\n",
    "#WE ARE USING THE IRIS DATASET FROM UCI MACHINE LEARNING REPOSITORY\n",
    "import pandas as pd\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris_data = pd.read_csv(url, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2609bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length sepal_length_category\n",
      "0             5.1                medium\n",
      "1             4.9                 small\n",
      "2             4.7                 small\n",
      "3             4.6                 small\n",
      "4             5.0                medium\n",
      "..            ...                   ...\n",
      "145           6.7                 large\n",
      "146           6.3                 large\n",
      "147           6.5                 large\n",
      "148           6.2                 large\n",
      "149           5.9                medium\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#FIRSTLY FOR CATEGOTIZATION WE WILL DEFINE THE THRESHOLDS\n",
    "small_threshold = 5.0\n",
    "medium_threshold = 6.0\n",
    "\n",
    "#WE WILL CREATE A NEW COLUMN CALLED 'sepal_length_category' AND CATEGORIZE EACH IRIS PLANT\n",
    "iris_data['sepal_length_category'] = ''\n",
    "for index, row in iris_data.iterrows():\n",
    "    sepal_length = row['sepal_length']\n",
    "    if sepal_length < small_threshold:\n",
    "        iris_data.at[index, 'sepal_length_category'] = 'small'\n",
    "    elif sepal_length < medium_threshold:\n",
    "        iris_data.at[index, 'sepal_length_category'] = 'medium'\n",
    "    else:\n",
    "        iris_data.at[index, 'sepal_length_category'] = 'large'\n",
    "\n",
    "#WE WILL NOW PRINT THE UPDATES DATAFRAME\n",
    "print(iris_data[['sepal_length', 'sepal_length_category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8035ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Petal Width for Each Class:\n",
      "{'Iris-setosa': 0.244, 'Iris-versicolor': 1.3259999999999998, 'Iris-virginica': 2.0260000000000002}\n"
     ]
    }
   ],
   "source": [
    "#NOW WE WILL CREATE A DICTIONARY TO STORE AVERAGE PETAL WIDTH FROM EACH CLASS\n",
    "average_petal_width_dict = {}\n",
    "\n",
    "#NOW WE WILL CALCULATE THE AVERAGE PETAL WIDTH FOR EACH CLASS\n",
    "for class_name in iris_data['class'].unique():\n",
    "    class_data = iris_data[iris_data['class'] == class_name]\n",
    "    average_petal_width = class_data['petal_width'].mean()\n",
    "    average_petal_width_dict[class_name] = average_petal_width\n",
    "\n",
    "#FINALLY WE WILL PRINT THE RESULTING DICTIONARY\n",
    "print(\"Average Petal Width for Each Class:\")\n",
    "print(average_petal_width_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9d57ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal Length-to-Width Ratios:\n",
      "[1.457142857142857, 1.6333333333333335, 1.46875, 1.4838709677419353, 1.3888888888888888, 1.3846153846153848, 1.352941176470588, 1.4705882352941178, 1.517241379310345, 1.5806451612903227, 1.4594594594594594, 1.411764705882353, 1.5999999999999999, 1.4333333333333333, 1.45, 1.2954545454545454, 1.3846153846153848, 1.457142857142857, 1.5000000000000002, 1.3421052631578947, 1.5882352941176472, 1.3783783783783783, 1.2777777777777777, 1.5454545454545454, 1.411764705882353, 1.6666666666666667, 1.4705882352941178, 1.4857142857142858, 1.5294117647058825, 1.46875, 1.5483870967741935, 1.5882352941176472, 1.2682926829268295, 1.3095238095238095, 1.5806451612903227, 1.5625, 1.5714285714285714, 1.5806451612903227, 1.4666666666666668, 1.5, 1.4285714285714286, 1.956521739130435, 1.375, 1.4285714285714286, 1.3421052631578947, 1.5999999999999999, 1.3421052631578947, 1.4374999999999998, 1.4324324324324322, 1.5151515151515151, 2.1875, 2.0, 2.2258064516129035, 2.3913043478260874, 2.3214285714285716, 2.035714285714286, 1.9090909090909092, 2.041666666666667, 2.2758620689655173, 1.9259259259259258, 2.5, 1.9666666666666668, 2.727272727272727, 2.103448275862069, 1.9310344827586206, 2.161290322580645, 1.8666666666666665, 2.148148148148148, 2.818181818181818, 2.2399999999999998, 1.84375, 2.1785714285714284, 2.52, 2.1785714285714284, 2.206896551724138, 2.1999999999999997, 2.428571428571429, 2.2333333333333334, 2.0689655172413794, 2.1923076923076925, 2.291666666666667, 2.291666666666667, 2.148148148148148, 2.222222222222222, 1.8, 1.7647058823529411, 2.161290322580645, 2.739130434782609, 1.8666666666666665, 2.2, 2.1153846153846154, 2.033333333333333, 2.230769230769231, 2.173913043478261, 2.074074074074074, 1.9000000000000001, 1.9655172413793105, 2.137931034482759, 2.04, 2.035714285714286, 1.9090909090909092, 2.148148148148148, 2.3666666666666667, 2.1724137931034484, 2.1666666666666665, 2.533333333333333, 1.9600000000000002, 2.5172413793103448, 2.68, 2.0, 2.03125, 2.3703703703703702, 2.2666666666666666, 2.2800000000000002, 2.0714285714285716, 2.0, 2.1666666666666665, 2.0263157894736845, 2.9615384615384617, 2.727272727272727, 2.15625, 2.0, 2.7500000000000004, 2.333333333333333, 2.0303030303030303, 2.25, 2.2142857142857144, 2.033333333333333, 2.285714285714286, 2.4, 2.6428571428571432, 2.0789473684210527, 2.285714285714286, 2.25, 2.346153846153846, 2.566666666666667, 1.8529411764705883, 2.064516129032258, 2.0, 2.2258064516129035, 2.161290322580645, 2.2258064516129035, 2.148148148148148, 2.125, 2.0303030303030303, 2.2333333333333334, 2.52, 2.1666666666666665, 1.823529411764706, 1.9666666666666668]\n"
     ]
    }
   ],
   "source": [
    "#FOR THE FINAL SEGMENT WE WILL CREATE A LIST OF SEPAL LENGTH-TO-WIDTH RATIOS USING LIST COMPREHENSION\n",
    "sepal_length_to_width_ratios = [sepal_length / sepal_width for sepal_length, sepal_width in zip(iris_data['sepal_length'], iris_data['sepal_width'])]\n",
    "\n",
    "#AT LAST WE WILL PRINT OUR FINAL RESULTING LIST\n",
    "print(\"Sepal Length-to-Width Ratios:\")\n",
    "print(sepal_length_to_width_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32f320",
   "metadata": {},
   "source": [
    "#### Submission Guidelines\n",
    "- Write your code in a Python script or a Jupyter Notebook.\n",
    "- Include comments to explain the purpose of your code and the logic behind your solutions.\n",
    "- Ensure your code is clean, well-organized, and follows Python best practices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1080dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
