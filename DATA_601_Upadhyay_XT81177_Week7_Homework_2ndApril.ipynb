{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9747d107",
   "metadata": {},
   "source": [
    "##### Name: Stuti Upadhyay\n",
    "##### Campus ID: XT81177\n",
    "##### Instructor: Chalachew Jemberie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b43683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "python_list = [1, 2, 3, 4, 5]\n",
    "numpy_array = np.array(python_list)\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480b090",
   "metadata": {},
   "source": [
    "What is the data type of the elements in the numpy array?\n",
    "- The data type of the elements in the NumPy array created from the Python list [1, 2, 3, 4, 5] is int. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44806614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "zeros_array = np.zeros((3, 4))\n",
    "print(zeros_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a96381",
   "metadata": {},
   "source": [
    "How would you create a NumPy array of ones instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ff2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ones_array = np.ones((3, 4))\n",
    "print(ones_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0895dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[2 3]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "# Accessing elements\n",
    "print(arr[0, 1])  # Prints the element at row 0, column 1\n",
    "# Slicing\n",
    "print(arr[:, 1:])  # Prints all rows and columns starting from column index 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df00bbd",
   "metadata": {},
   "source": [
    "How would you perform element-wise addition of two NumPy arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4680d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 10 12]\n",
      " [14 16 18]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "arr2 = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "result = arr1 + arr2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab494d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with Python lists: 0.062154293060302734\n",
      "Time taken with NumPy arrays: 0.00793766975402832\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Using Python lists\n",
    "start_time = time.time()\n",
    "python_list1 = list(range(1000000))\n",
    "python_list2 = list(range(1000000))\n",
    "result = [a + b for a, b in zip(python_list1, python_list2)]\n",
    "end_time = time.time()\n",
    "print(\"Time taken with Python lists:\", end_time - start_time)\n",
    "\n",
    "# Using NumPy arrays\n",
    "start_time = time.time()\n",
    "numpy_array1 = np.arange(1000000)\n",
    "numpy_array2 = np.arange(1000000)\n",
    "result = numpy_array1 + numpy_array2\n",
    "end_time = time.time()\n",
    "print(\"Time taken with NumPy arrays:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3aad53",
   "metadata": {},
   "source": [
    "Compare the time taken with Python lists and NumPy arrays. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163764c8",
   "metadata": {},
   "source": [
    "When comparing the time taken for element-wise addition:\n",
    "- Operations with NumPy arrays are significantly faster compared to equivalent operations with Python lists.\n",
    "- NumPy arrays leverage optimized C implementations, resulting in faster computations compared to Python lists, which are native Python objects.\n",
    "- This speed difference highlights the efficiency and performance benefits of using NumPy arrays for numerical computations and array operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e150fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [-4.5  5. ]\n"
     ]
    }
   ],
   "source": [
    "# Ax = b\n",
    "A = np.array([[2, 3], [4, 5]])\n",
    "b = np.array([6, 7])\n",
    "\n",
    "# Solve for x\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"Solution:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca677d94",
   "metadata": {},
   "source": [
    "What would be the solution if the system of equations has no solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e229446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [-4.5  5. ]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 3], [4, 5]])\n",
    "b = np.array([6, 7])\n",
    "\n",
    "try:\n",
    "    x = np.linalg.solve(A, b)\n",
    "    print(\"Solution:\", x)\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d029f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (m): 0.9999999999999999\n",
      "Intercept (c): 0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "# Given data points (x, y)\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Construct matrix X\n",
    "X = np.vstack([x, np.ones(len(x))]).T\n",
    "\n",
    "# Solve for m and c in y = mx + c\n",
    "m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "print(\"Slope (m):\", m)\n",
    "print(\"Intercept (c):\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d382d4",
   "metadata": {},
   "source": [
    "How would you visualize the linear regression line with the given data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "494837a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given data points (x, y)\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Construct matrix X\n",
    "X = np.vstack([x, np.ones(len(x))]).T\n",
    "\n",
    "# Solve for m and c in y = mx + c\n",
    "m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(x, y, label='Data Points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x, m*x + c, 'r', label='Regression Line')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "128141f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of matrix multiplication:\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication: C = A * B\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "C = np.dot(A, B)\n",
    "print(\"Result of matrix multiplication:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df899f1e",
   "metadata": {},
   "source": [
    "What is the shape of the resulting matrix C?\n",
    "- The shape of C will be(2,2) which means it will also have 2 rows and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e5a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose of matrix A:\n",
      "[[1 3 5]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "# Transpose of a matrix\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "transpose_A = np.transpose(A)\n",
    "print(\"Transpose of matrix A:\")\n",
    "print(transpose_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda2355",
   "metadata": {},
   "source": [
    " How does the shape of the transposed matrix change compared to the original matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca254782",
   "metadata": {},
   "source": [
    "The shape of the transposed matrix is obtained by swapping the dimensions of the original matrix. \n",
    "\n",
    "For the given matrix \\( A \\):\n",
    "- Original shape: \\( (3, 2) \\) (3 rows, 2 columns).\n",
    "\n",
    "When you compute the transpose of matrix \\( A \\), the shape changes to \\( (2, 3) \\) (2 rows, 3 columns). \n",
    "\n",
    "So, comparing the original matrix \\( A \\) with its transpose \\( A^T \\):\n",
    "- Original matrix shape: \\( (3, 2) \\)\n",
    "- Transposed matrix shape: \\( (2, 3) \\)\n",
    "\n",
    "In general, the shape of the transposed matrix is obtained by swapping the number of rows with the number of columns of the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdddca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: [1 2 3]\n",
      "Last column: [3 6 9]\n",
      "Sub-matrix from row 1 to 2 and column 1 to 2:\n",
      "[[5 6]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Slicing and indexing NumPy arrays\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"First row:\", arr[0])\n",
    "print(\"Last column:\", arr[:, -1])\n",
    "print(\"Sub-matrix from row 1 to 2 and column 1 to 2:\")\n",
    "print(arr[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4120490",
   "metadata": {},
   "source": [
    "How would you extract all even numbers from the given array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "440e0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even numbers: [2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "even_numbers = arr[arr % 2 == 0]\n",
    "print(\"Even numbers:\", even_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3d2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise addition:\n",
      "[[ 6  8]\n",
      " [10 12]]\n",
      "Element-wise multiplication:\n",
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise operations with NumPy arrays\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6], [7, 8]])\n",
    "print(\"Element-wise addition:\")\n",
    "print(arr1 + arr2)\n",
    "print(\"Element-wise multiplication:\")\n",
    "print(arr1 * arr2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1dbd0",
   "metadata": {},
   "source": [
    "How would you perform element-wise division of two NumPy arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ba5fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise division:\n",
      "[[0.14285714 0.25       0.33333333]\n",
      " [0.4        0.45454545 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "arr3 = np.array([[1, 2], [3, 4]])\n",
    "arr4= np.array([[5, 6], [7, 8]])\n",
    "\n",
    "element_wise_division = arr1 / arr2\n",
    "print(\"Element-wise division:\")\n",
    "print(element_wise_division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e75d2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Reshaped array:\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping NumPy arrays\n",
    "arr5 = np.arange(1, 13)\n",
    "reshaped_arr = arr.reshape(3, 4)\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "print(\"Reshaped array:\")\n",
    "print(reshaped_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c27f4d",
   "metadata": {},
   "source": [
    "What happens if the reshaping dimensions don't match the number of elements in the array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4861942",
   "metadata": {},
   "source": [
    "- If the reshaping dimensions don't match the number of elements in the array, NumPy will raise a `ValueError`. Specifically, if the total number of elements in the original array does not match the total number of elements in the desired shape, the reshape operation is not possible, and a `ValueError` will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e343e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in the array:\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Finding unique elements in a NumPy array\n",
    "arr = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])\n",
    "unique_elements = np.unique(arr)\n",
    "print(\"Unique elements in the array:\")\n",
    "print(unique_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487852e5",
   "metadata": {},
   "source": [
    "How would you count the frequency of each unique element in the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "736bf0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in the array:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Frequency of each unique element:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "arr6 = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])\n",
    "unique_elements, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "print(\"Unique elements in the array:\")\n",
    "print(unique_elements)\n",
    "\n",
    "print(\"Frequency of each unique element:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc48a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a random dataset\n",
    "data = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "\n",
    "# Mean normalization\n",
    "mean = np.mean(data, axis=0)\n",
    "std = np.std(data, axis=0)\n",
    "normalized_data = (data - mean) / std\n",
    "\n",
    "# Slicing and indexing\n",
    "sample = normalized_data[0]  # Accessing the first sample\n",
    "feature_3 = normalized_data[:, 2]  # Accessing the third feature for all samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a39992",
   "metadata": {},
   "source": [
    "How does mean normalization help in preprocessing data for machine learning?\n",
    "What does slicing and indexing help achieve in machine learning tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239374b",
   "metadata": {},
   "source": [
    "Mean normalization is a preprocessing technique used in machine learning to standardize the features of a dataset. It involves subtracting the mean of each feature from the dataset and then dividing by the standard deviation of the feature. This process centers the data around zero and scales it to have a standard deviation of 1. \n",
    "\n",
    "Mean normalization helps in preprocessing data for machine learning in the following ways:\n",
    "\n",
    "1. **Improved convergence**: Mean normalization can help gradient descent algorithms converge more quickly because it reduces the scale of the input features, preventing some features from dominating others during the learning process.\n",
    "\n",
    "2. **Better performance**: It can lead to better performance of machine learning algorithms, especially those sensitive to feature scales, such as linear regression, logistic regression, and support vector machines.\n",
    "\n",
    "3. **Reduced numerical instability**: Mean normalization can help in reducing numerical instability issues that may arise due to large feature values.\n",
    "\n",
    "Slicing and indexing are fundamental operations in machine learning tasks that help achieve various objectives:\n",
    "\n",
    "1. **Accessing data**: Slicing and indexing allow you to access specific subsets of data within a dataset. For example, you can access individual samples or features of a dataset as demonstrated in the code provided.\n",
    "\n",
    "2. **Feature selection**: Slicing and indexing enable you to select specific features from the dataset that are relevant to the task at hand. This helps in reducing the dimensionality of the data and focusing on the most informative features.\n",
    "\n",
    "3. **Data manipulation**: Slicing and indexing allow you to manipulate the data in various ways, such as filtering out noisy or irrelevant samples, creating new features, or reshaping the dataset as needed for different machine learning algorithms.\n",
    "\n",
    "Overall, slicing and indexing are essential tools for data exploration, preprocessing, and feature engineering in machine learning tasks, enabling researchers and practitioners to effectively work with datasets and prepare them for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae26e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generating synthetic data\n",
    "X = np.random.rand(100, 10)  # Features\n",
    "Y = np.random.randint(0, 2, size=(100,))  # Labels\n",
    "\n",
    "# Matrix multiplication\n",
    "theta = np.random.rand(10)  # Coefficients\n",
    "predictions = np.dot(X, theta)\n",
    "\n",
    "# Sigmoid function\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "probabilities = sigmoid(predictions)\n",
    "\n",
    "# Loss calculation\n",
    "loss = -np.mean(Y * np.log(probabilities) + (1 - Y) * np.log(1 - probabilities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692ba90",
   "metadata": {},
   "source": [
    "How is matrix multiplication used in machine learning algorithms like linear regression or logistic regression?\n",
    "What is the significance of the sigmoid function in logistic regression?\n",
    "How does the loss function help in evaluating the performance of a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30ab19",
   "metadata": {},
   "source": [
    "Matrix multiplication plays a crucial role in machine learning algorithms like linear regression and logistic regression:\n",
    "\n",
    "1. **Linear Regression**: In linear regression, matrix multiplication is used to calculate predictions for the target variable based on the input features and model coefficients. The predicted values are obtained by multiplying the feature matrix \\(X\\) by the coefficient vector \\(\\theta\\), where \\(X\\) contains the input features and \\(\\theta\\) contains the model coefficients.\n",
    "\n",
    "2. **Logistic Regression**: In logistic regression, matrix multiplication is used similarly to linear regression to calculate predictions. However, instead of directly predicting the target variable, logistic regression predicts the probability that a given input belongs to a certain class. The predicted probabilities are obtained by applying the sigmoid function to the output of the linear combination of features and coefficients.\n",
    "\n",
    "The sigmoid function is significant in logistic regression for several reasons:\n",
    "\n",
    "1. **Output probability**: The sigmoid function maps the output of the linear combination of features and coefficients to a value between 0 and 1, which can be interpreted as the probability that a given input belongs to a certain class.\n",
    "\n",
    "2. **Log-odds transformation**: The sigmoid function represents the log-odds or logit transformation, which converts the linear combination of features and coefficients into a probability.\n",
    "\n",
    "3. **Differentiability**: The sigmoid function is differentiable, which is essential for gradient-based optimization algorithms used to train logistic regression models.\n",
    "\n",
    "The loss function is used to evaluate the performance of a machine learning model by quantifying the difference between the model's predictions and the actual labels in the training data. In logistic regression, the commonly used loss function is the cross-entropy loss (also known as log loss), which measures the difference between the predicted probabilities and the true labels.\n",
    "\n",
    "The significance of the loss function lies in its ability to provide a quantitative measure of how well the model is performing. By minimizing the loss function during training, the model's parameters (coefficients in the case of logistic regression) are adjusted to make better predictions, ultimately leading to a more accurate model. The goal is to find the set of parameters that minimizes the loss, indicating that the model's predictions are as close to the true labels as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f093ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Adding a bias term to a dataset\n",
    "data = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "bias = np.random.rand(1, 5)  # Bias term for each feature\n",
    "\n",
    "# Broadcasting\n",
    "data_with_bias = data + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e3e43",
   "metadata": {},
   "source": [
    "How does broadcasting simplify the addition of a bias term to each sample in the dataset?\n",
    "Can you explain how broadcasting handles operations between arrays with different shapes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb963b",
   "metadata": {},
   "source": [
    "Broadcasting simplifies the addition of a bias term to each sample in the dataset by allowing NumPy to automatically expand or \"broadcast\" the bias term to match the shape of the dataset. In this context, broadcasting enables NumPy to add the bias term to each sample's corresponding feature without explicitly repeating or duplicating the bias term for each sample.\n",
    "\n",
    "Here's how broadcasting works in the context of adding a bias term to a dataset:\n",
    "\n",
    "1. **Broadcasting**: When performing the addition operation `data + bias`, NumPy recognizes that the shapes of the two arrays (`data` and `bias`) are different. The `data` array has a shape of `(100, 5)` (100 samples, 5 features), while the `bias` array has a shape of `(1, 5)` (1 row, 5 columns).\n",
    "\n",
    "2. **Alignment**: NumPy automatically aligns the dimensions of the two arrays to perform element-wise addition. Since the second dimension (number of features) of both arrays matches, NumPy broadcasts the bias term along the first dimension (number of samples) to match the shape of the `data` array.\n",
    "\n",
    "3. **Implicit repetition**: Although the bias term has only one row, NumPy implicitly repeats or \"broadcasts\" it across all 100 rows of the `data` array during the addition operation. This process ensures that the bias term is added to each sample's corresponding feature without the need for explicit loops or manual repetition.\n",
    "\n",
    "In summary, broadcasting simplifies the addition of a bias term to each sample in the dataset by automatically aligning and repeating the bias term across the appropriate dimensions of the dataset array, resulting in concise and efficient code.\n",
    "\n",
    "Regarding operations between arrays with different shapes, broadcasting allows NumPy to perform element-wise operations between arrays of different shapes by implicitly expanding or \"broadcasting\" the smaller array to match the shape of the larger array. Broadcasting follows certain rules:\n",
    "\n",
    "1. **Dimensions compatibility**: The dimensions of the arrays are compared element-wise, starting from the trailing dimensions and working backward. The dimensions are compatible if they are equal or one of them is 1.\n",
    "\n",
    "2. **Expansion**: If the dimensions are not equal and not 1, NumPy expands the array with smaller dimensions to match the shape of the larger array by replicating the elements along the dimensions where the size is 1.\n",
    "\n",
    "3. **Element-wise operation**: After broadcasting, NumPy performs the element-wise operation between the expanded arrays.\n",
    "\n",
    "By leveraging broadcasting, NumPy enables concise and efficient operations on arrays with different shapes, simplifying the code and improving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0cc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generating synthetic data\n",
    "X = np.random.rand(100, 5)  # Features\n",
    "Y = np.random.rand(100)  # Target variable\n",
    "\n",
    "# Training a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Making predictions\n",
    "predictions = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0ce11",
   "metadata": {},
   "source": [
    "How does NumPy's compatibility with libraries like scikit-learn simplify the implementation of machine learning algorithms?\n",
    "What are some other popular machine learning libraries that utilize NumPy arrays as input data structures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aeef56",
   "metadata": {},
   "source": [
    "NumPy's compatibility with libraries like scikit-learn simplifies the implementation of machine learning algorithms in several ways:\n",
    "\n",
    "1. **Efficient data handling**: NumPy provides efficient data structures and operations for handling numerical data, making it suitable for processing large datasets commonly encountered in machine learning tasks. Libraries like scikit-learn leverage NumPy arrays as input data structures, enabling seamless integration with existing data processing pipelines.\n",
    "\n",
    "2. **Unified interface**: By utilizing NumPy arrays as input data structures, machine learning libraries can maintain a unified interface for data handling and manipulation. This facilitates interoperability between different components of machine learning pipelines and simplifies the development and maintenance of machine learning systems.\n",
    "\n",
    "3. **Performance optimization**: NumPy's underlying implementation in C enables efficient memory management and optimized numerical computations, leading to improved performance of machine learning algorithms. Libraries like scikit-learn leverage NumPy's performance optimizations to achieve faster training and prediction times.\n",
    "\n",
    "Some other popular machine learning libraries that utilize NumPy arrays as input data structures include:\n",
    "\n",
    "- TensorFlow: An open-source machine learning framework developed by Google that is widely used for building deep learning models. TensorFlow provides support for NumPy arrays as input data structures, allowing seamless integration with NumPy-based data processing pipelines.\n",
    "\n",
    "- PyTorch: A deep learning framework developed by Facebook that is known for its dynamic computation graph and flexibility. PyTorch supports NumPy arrays as input data structures, enabling easy data manipulation and integration with NumPy-based workflows.\n",
    "\n",
    "- Keras: A high-level neural networks API that runs on top of TensorFlow, Theano, or Microsoft Cognitive Toolkit (CNTK). Keras provides support for NumPy arrays as input data structures, making it easy to build and train deep learning models using NumPy-based data pipelines.\n",
    "\n",
    "Overall, NumPy's compatibility with popular machine learning libraries simplifies the implementation of machine learning algorithms and enables efficient data handling, performance optimization, and interoperability across different components of machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05130494",
   "metadata": {},
   "source": [
    "### **1. Linear Regression and Normal Equations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951a164",
   "metadata": {},
   "source": [
    "\n",
    "*Question*: Explain how the normal equations and linear algebra are used to solve linear regression problems.\n",
    "\n",
    "*Solution*: \n",
    "Linear regression aims to find a linear relationship between input features and a target variable. The normal equations are a method for finding the coefficients of the linear regression model.\n",
    "\n",
    "Given a dataset with input features X (a matrix) and target values y (a vector), the linear regression model can be represented as:\n",
    "\n",
    "    y = X * θ\n",
    "\n",
    "Where:\n",
    "- `y` is the target variable.\n",
    "- `X` is the feature matrix where each row represents an observation, and each column represents a feature.\n",
    "- `θ` is the vector of coefficients (including the intercept).\n",
    "\n",
    "To find the optimal coefficients θ, we can use the normal equations:\n",
    "\n",
    "    X^T * X * θ = X^T * y\n",
    "\n",
    "Where:\n",
    "- `X^T` is the transpose of the feature matrix X.\n",
    "- `X^T * X` is a square matrix.\n",
    "- `X^T * y` is a vector.\n",
    "\n",
    "To solve for θ, we can use the following equation:\n",
    "\n",
    "    θ = (X^T * X)^(-1) * X^T * y\n",
    "\n",
    "This equation can be implemented in Python using NumPy as follows:\n",
    "\n",
    "Keep in mind that while matrix inversion is a valid method for solving linear equations, it may not always be the most efficient or numerically stable approach for large or ill-conditioned matrices. Numerical libraries like NumPy often provide specialized functions for solving linear systems that are more stable and efficient in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8479ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (theta): [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y = np.array([2, 3, 4])\n",
    "\n",
    "# Calculate the coefficients using the normal equations\n",
    "X_transpose = np.transpose(X)\n",
    "theta = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(y)\n",
    "print(\"Coefficients (theta):\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb317dbd",
   "metadata": {},
   "source": [
    "Question1: Consider a simple linear regression problem where we want to predict house prices based on the number of bedrooms. Please solve theta using the abobe example and disuss your result "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa44d1e4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dummy data\n",
    "bedrooms = np.array([1, 2, 3, 4, 5])\n",
    "house_prices = np.array([200, 300, 400, 450, 500])\n",
    "\n",
    "# Create the feature matrix X with a column of ones for the intercept\n",
    "X = np.column_stack((np.ones_like(bedrooms), bedrooms))\n",
    "\n",
    "# Calculate the coefficients using the normal equations\n",
    "X_transpose = ------\n",
    "theta = np.linalg.inv(------------------)\n",
    "\n",
    "print(\"Coefficients (theta):\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ed08e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (theta): [145.  75.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "bedrooms = np.array([1, 2, 3, 4, 5])\n",
    "house_prices = np.array([200, 300, 400, 450, 500])\n",
    "\n",
    "# Create the feature matrix X with a column of ones for the intercept\n",
    "X = np.column_stack((np.ones_like(bedrooms), bedrooms))\n",
    "\n",
    "# Calculate the coefficients using the normal equations\n",
    "X_transpose = np.transpose(X)\n",
    "theta = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(house_prices)\n",
    "\n",
    "print(\"Coefficients (theta):\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad011d46",
   "metadata": {},
   "source": [
    "### **2.Matrix Inversion and Linear Equations**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45d440",
   "metadata": {},
   "source": [
    "\n",
    "Question: Discuss the use of matrix inversion to solve systems of linear equations.\n",
    "\n",
    "Solution:\n",
    "Matrix inversion is a technique used to solve systems of linear equations of the form Ax = b, where A is a square matrix, x is the vector of unknowns, and b is the right-hand side vector.\n",
    "\n",
    "The solution to the system of equations can be found using matrix inversion as follows:\n",
    "\n",
    "1. Given the equation Ax = b, we want to solve for x.\n",
    "2. Multiply both sides of the equation by the inverse of matrix A: A^(-1).\n",
    "3. This gives us A^(-1) * (Ax) = A^(-1) * b.\n",
    "4. Since A^(-1) * A is the identity matrix (I), we have Ix = A^(-1) * b.\n",
    "5. Since Ix is simply x, we have x = A^(-1) * b.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d8d38",
   "metadata": {},
   "source": [
    "\n",
    " In data science, how can matrix inversion be applied to solve a system of linear equations? Provide a basic example using Python and NumPy.\n",
    " \n",
    "Matrix inversion is a technique used in data science to solve systems of linear equations efficiently. This is commonly applied in various fields, including statistics, machine learning, and optimization. Matrix inversion is used when the coefficient matrix is invertible (i.e., its determinant is non-zero).\n",
    "\n",
    "\n",
    "Let's consider a simple example of solving a system of linear equations using matrix inversion:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Coefficient matrix A\n",
    "A = np.array([[2, 3],\n",
    "              [4, 5]])\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([8, 10])\n",
    "\n",
    "# Check if the matrix A is invertible (non-singular)\n",
    "if np.linalg.det(A) != 0:\n",
    "    # Solve for x using matrix inversion\n",
    "    x = np.linalg.inv(A).dot(b)\n",
    "    print(\"Solution (x, y):\", x)\n",
    "else:\n",
    "    print(\"Matrix A is singular (not invertible).\")\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "1. We define the coefficient matrix `A` representing the coefficients of `x` and `y` in a system of linear equations.\n",
    "\n",
    "2. We define the right-hand side vector `b` containing the constants on the right-hand side of the equations.\n",
    "\n",
    "3. We check if the matrix `A` is invertible by verifying that its determinant is non-zero. If the determinant is zero, the matrix is singular and cannot be inverted.\n",
    "\n",
    "4. If `A` is invertible, we use NumPy to calculate the solution vector `x` by performing matrix inversion and then multiplying it by `b`.\n",
    "\n",
    "5. We print the values of `x` and `y`, which represent the solutions to the system of linear equations.\n",
    "\n",
    "This example demonstrates how matrix inversion can be applied to solve a basic system of linear equations, which is a fundamental concept in data science and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python example using NumPy to solve a system of linear equations using matrix inversion:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Coefficient matrix A\n",
    "A = np.array([[2, 3], [4, 5]])\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([7, 10])\n",
    "\n",
    "# Solve for x using matrix inversion\n",
    "x = np.linalg.inv(A).dot(b)\n",
    "\n",
    "print(\"Solution (x):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b99c9",
   "metadata": {},
   "source": [
    "\n",
    "Question2:  Given the following system of linear equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b56e9",
   "metadata": {},
   "source": [
    "```\n",
    "2x + 3y = 8\n",
    "4x - y  = 7\n",
    "```\n",
    "Use Python and NumPy to find the values of `x` and `y` that satisfy these equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a762797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution (x, y): 2.0714285714285716 1.2857142857142856\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Coefficient matrix A\n",
    "A = np.array([[2, 3], [4, -1]])\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([8, 7])\n",
    "\n",
    "# Solve for x and y using matrix inversion\n",
    "x, y = np.linalg.inv(A).dot(b)\n",
    "\n",
    "print(\"Solution (x, y):\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c543945",
   "metadata": {},
   "source": [
    "Describe how matrix inversion can be used to solve the linear regression problem, and discuss any limitations or assumptions associated with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3608d",
   "metadata": {},
   "source": [
    "To solve the given system of linear equations using Python and NumPy, we can follow these steps:\n",
    "\n",
    "1. Define the coefficient matrix \\( A \\) and the right-hand side vector \\( b \\).\n",
    "2. Use NumPy's linear algebra module (`np.linalg`) to solve the system of equations using matrix inversion.\n",
    "3. Print the values of \\( x \\) and \\( y \\) that satisfy the equations.\n",
    "\n",
    "This will output the values of \\( x \\) and \\( y \\) that satisfy the given system of linear equations.\n",
    "\n",
    "Now, regarding the use of matrix inversion to solve the linear regression problem:\n",
    "\n",
    "Matrix inversion can be used to solve the linear regression problem when we have a system of linear equations representing the relationship between the input features and the target variable. In linear regression, we typically have a feature matrix \\( X \\) containing the input features and a target vector \\( y \\), and we seek to find the coefficient vector \\( \\theta \\) that minimizes the error between the predicted values \\( X\\theta \\) and the actual target values \\( y \\).\n",
    "\n",
    "To solve for \\( \\theta \\), we set up the normal equations \\( X^TX\\theta = X^Ty \\), where \\( X^T \\) denotes the transpose of \\( X \\). We can then solve this system of equations using matrix inversion: \\( \\theta = (X^TX)^{-1}X^Ty \\).\n",
    "\n",
    "However, using matrix inversion for linear regression has some limitations and assumptions:\n",
    "\n",
    "1. **Computational complexity**: Matrix inversion has a computational complexity of \\( O(n^3) \\), where \\( n \\) is the number of features. This can be computationally expensive for large datasets, especially when \\( n \\) is large.\n",
    "\n",
    "2. **Numerical stability**: Matrix inversion can be numerically unstable, especially when the matrix \\( X^TX \\) is ill-conditioned or singular. In such cases, small numerical errors in the input data or rounding errors can lead to large errors in the solution.\n",
    "\n",
    "3. **Assumption of full rank**: Matrix inversion assumes that the matrix \\( X^TX \\) is full rank, i.e., it has linearly independent columns. If the matrix is not full rank, it may not be invertible, and matrix inversion cannot be used.\n",
    "\n",
    "Due to these limitations, alternative methods such as gradient descent or singular value decomposition (SVD) are often preferred for solving linear regression problems, especially for large datasets or when the matrix \\( X^TX \\) is ill-conditioned. These methods offer better numerical stability and scalability compared to matrix inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f68fa1",
   "metadata": {},
   "source": [
    "## 3. Linear Regression with Matrix Inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0b972",
   "metadata": {},
   "source": [
    "Question3:  You are working on a data science project where you need to perform linear regression to predict a target variable 'y' based on multiple features 'X1', 'X2', and 'X3'. Your goal is to use matrix inversion to find the coefficients ('theta') of the linear regression model. The dataset dummy_data.csv contains the following data:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fefcaeb7",
   "metadata": {},
   "source": [
    "X1, X2, X3, y\n",
    "1, 2, 3, 12\n",
    "2, 3, 4, 18\n",
    "3, 4, 5, 24\n",
    "4, 5, 6, 30\n",
    "5, 6, 7, 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8816a54",
   "metadata": {},
   "source": [
    "Write Python code to perform the following tasks:\n",
    "\n",
    "- Load the dataset from dummy_data.csv into a Pandas DataFrame.\n",
    "- Create a feature matrix 'X' by selecting the columns 'X1', 'X2', and 'X3'.\n",
    "- Create a target vector 'y' by selecting the 'y' column.\n",
    "- Add a column of ones to the feature matrix 'X' to represent the intercept term.\n",
    "- Use matrix inversion to calculate the coefficients 'theta' of the linear regression model.\n",
    "- Print the coefficients 'theta'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d72819e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  X3   y\n",
      "0   1   2   3  12\n",
      "1   2   3   4  18\n",
      "2   3   4   5  24\n",
      "3   4   5   6  30\n",
      "4   5   6   7  36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from dummy_data.csv into a Pandas DataFrame\n",
    "df = pd.read_csv('dummy_data.csv')\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4eeb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature matrix 'X' by selecting the columns 'X1', 'X2', and 'X3'\n",
    "X = df[['X1', 'X2', 'X3']]\n",
    "\n",
    "# Create a target vector 'y' by selecting the 'y' column\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "134d5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (theta): [ 62.8125 -31.5    -21.      32.25  ]\n"
     ]
    }
   ],
   "source": [
    "# Add a column of ones to the feature matrix 'X' to represent the intercept term\n",
    "X['intercept'] = 1\n",
    "\n",
    "# Use matrix inversion to calculate the coefficients 'theta' of the linear regression model\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "# Print the coefficients 'theta'\n",
    "print(\"Coefficients (theta):\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beb199",
   "metadata": {},
   "source": [
    "## 4: Matrix Inversion and Eigenvlaues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82e4fc",
   "metadata": {},
   "source": [
    "\n",
    "**Question 4: Matrix Inversion and Ill-Conditioned Matrices**\n",
    "\n",
    "Explain the concept of ill-conditioned matrices in the context of matrix inversion. Provide an example of an ill-conditioned matrix and discuss why matrix inversion can lead to numerical instability for such matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61481d1b",
   "metadata": {},
   "source": [
    "**Question 5: Eigenvalues and Eigenvectors**\n",
    "\n",
    " In data science, why are eigenvalues and eigenvectors important? Provide an example of how they can be applied in a practical data analysis scenario.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab598f38",
   "metadata": {},
   "source": [
    "**Answer 4: Matrix Inversion and Ill-Conditioned Matrices**\n",
    "\n",
    "In the context of matrix inversion, an ill-conditioned matrix is a matrix that is nearly singular or has a high condition number. A condition number measures how sensitive the output of a function (in this case, matrix inversion) is to small changes or perturbations in the input.\n",
    "\n",
    "An ill-conditioned matrix can cause numerical instability during matrix inversion because small errors or inaccuracies in the input data can be greatly amplified in the output. This can lead to large errors or inaccuracies in the inverted matrix, making the solution unreliable.\n",
    "\n",
    "An example of an ill-conditioned matrix is a matrix where the rows or columns are nearly linearly dependent, leading to a condition number close to infinity. For example, consider the following matrix:\n",
    "\n",
    "\\[\n",
    "A = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1 + \\epsilon\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "where ϵ is a small positive number. This matrix is nearly singular because the second row is almost equal to the first row, but with a small perturbation. As a result, the condition number of matrix \\( A \\) becomes very large, leading to numerical instability during matrix inversion.\n",
    "\n",
    "Matrix inversion can lead to numerical instability for ill-conditioned matrices because small changes in the input data can result in large changes in the output, making the solution highly sensitive to errors or inaccuracies in the input.\n",
    "\n",
    "**Answer 5: Eigenvalues and Eigenvectors**\n",
    "\n",
    "Eigenvalues and eigenvectors are important in data science for several reasons:\n",
    "\n",
    "1. **Dimensionality reduction**: Eigenvalues and eigenvectors are used in principal component analysis (PCA), a popular technique for dimensionality reduction. PCA identifies the directions (eigenvectors) in which the data varies the most and projects the data onto these directions, effectively reducing the dimensionality while preserving the most important information.\n",
    "\n",
    "2. **Feature extraction**: Eigenvalues and eigenvectors can be used to extract features from data by transforming the original data into a new feature space defined by the eigenvectors. This transformation can help uncover underlying patterns or structures in the data that may not be apparent in the original feature space.\n",
    "\n",
    "3. **Spectral analysis**: Eigenvalues and eigenvectors are used in spectral clustering, a clustering technique that partitions data into clusters based on the spectral properties of the data's affinity matrix. Spectral clustering leverages the eigenvalues and eigenvectors of the affinity matrix to identify meaningful clusters in the data.\n",
    "\n",
    "4. **Linear transformations**: Eigenvalues and eigenvectors represent the scaling factors and directions of linear transformations of a matrix. In data analysis, eigenvalues and eigenvectors can be used to understand how data is transformed by linear operations, such as rotations, stretches, or compressions.\n",
    "\n",
    "In a practical data analysis scenario, eigenvalues and eigenvectors can be applied in various ways. For example, in image processing, eigenvectors can be used to represent the principal directions of variation in an image dataset, while eigenvalues can indicate the importance or magnitude of these directions. This information can be used for tasks such as image compression, denoising, or feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e492fa9",
   "metadata": {},
   "source": [
    "## Bonus Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5480f",
   "metadata": {},
   "source": [
    "Question: Explain what a covariance matrix is in the context of linear algebra. How is it calculated, and what does it represent in data analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d11cb",
   "metadata": {},
   "source": [
    "In linear algebra, a covariance matrix summarizes the relationships between variables in a dataset. It's a square matrix where the diagonal elements represent the variances of individual variables, and off-diagonal elements represent the covariances between pairs of variables. It's calculated by taking the average of the product of the deviations of each variable from its mean. In data analysis, the covariance matrix helps understand how variables change together. It's used in principal component analysis (PCA) for dimensionality reduction and to identify the principal axes of variation in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffade7",
   "metadata": {},
   "source": [
    "Question: What is a correlation matrix, and how does it relate to the covariance matrix? How is it calculated, and why is it often preferred in data analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e691745",
   "metadata": {},
   "source": [
    "A correlation matrix shows standardized measures of linear dependence between variables in a dataset, ranging from -1 to 1. It is calculated by dividing each element of the covariance matrix by the product of the standard deviations of the corresponding variables. The correlation matrix is preferred in data analysis because it provides easier interpretation, comparability across datasets, scale invariance, and a concise summary of relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c3f8b",
   "metadata": {},
   "source": [
    "Question: Provide examples of how covariance and correlation matrices are used in data science and statistical analysis. How can they help in understanding data relationships and making decisions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec5cb",
   "metadata": {},
   "source": [
    "Covariance and correlation matrices are used in data science and statistical analysis to understand relationships between variables and make decisions:\n",
    "\n",
    "1. **Exploring Relationships**: Covariance and correlation matrices help to identify the strength and direction of relationships between variables. For example, in finance, covariance matrices are used to analyze the relationships between asset returns, while correlation matrices help identify which variables move together.\n",
    "\n",
    "2. **Dimensionality Reduction**: In techniques like principal component analysis (PCA), covariance and correlation matrices are used to identify the principal components of variation in high-dimensional datasets. These components can then be used to reduce dimensionality while preserving as much information as possible.\n",
    "\n",
    "3. **Multivariate Analysis**: Covariance and correlation matrices are central to multivariate statistical techniques such as linear regression and discriminant analysis. They provide insights into how multiple variables interact and influence each other.\n",
    "\n",
    "4. **Identifying Redundancy**: High values in covariance or correlation matrices may indicate redundancy among variables. Removing redundant variables can simplify models and improve interpretability without sacrificing predictive performance.\n",
    "\n",
    "5. **Detecting Collinearity**: High correlation values between pairs of variables in the correlation matrix may indicate multicollinearity, which can lead to instability in regression models. Identifying and addressing multicollinearity can improve the reliability of statistical analyses and model predictions.\n",
    "\n",
    "In summary, covariance and correlation matrices are essential tools in data science and statistical analysis for understanding relationships between variables, identifying patterns, reducing dimensionality, and making informed decisions based on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa41055",
   "metadata": {},
   "source": [
    "Question: Write Python code to calculate the covariance between two sets of data, data1 and data2. Assume that both data1 and data2 are NumPy arrays of the same length."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd114f3e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate the covariance\n",
    "------\n",
    "\n",
    "print(\"Covariance:\", covariance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a890052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance: -2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate the covariance\n",
    "covariance = np.cov(data1, data2)[0, 1]\n",
    "\n",
    "print(\"Covariance:\", covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0643047",
   "metadata": {},
   "source": [
    "Question: Write Python code to calculate the Pearson correlation coefficient (correlation) between two sets of data, data1 and data2. Assume that both data1 and data2 are NumPy arrays of the same length."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e237de58",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "\n",
    "\n",
    "print(\"Correlation Coefficient:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "724e0451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation = np.corrcoef(data1, data2)[0, 1]\n",
    "\n",
    "print(\"Correlation Coefficient:\", correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
