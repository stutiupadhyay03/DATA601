{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c3ad29",
   "metadata": {},
   "source": [
    "#### Name: Stuti Upadhyay\n",
    "#### Campus ID: XT81177\n",
    "#### Instructor: Chalachew Jemberie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fc9a5",
   "metadata": {},
   "source": [
    "# Week3 -Python Basic Skills on Real Datasets\n",
    "\n",
    "The homework assignment is focus on foundational Python skills, using built-in functions and data structures without relying on external libraries like `pandas` or visualization tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8778551",
   "metadata": {},
   "source": [
    "## Homework1:Analyzing Census Income Data\n",
    "\n",
    "**Objective**: Write Python functions to load, process, and analyze a subset of the \"Adult\" (Census Income) dataset to extract insights using only basic Python data structures and functions.\n",
    "\n",
    "\n",
    "We'll use the **\"Adult\" dataset** for a data analysis task that can be completed with basic Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a876b2",
   "metadata": {},
   "source": [
    "#### Task Overview\n",
    "\n",
    "1. **Data Loading and Processing**:\n",
    "   - Write a function to read the dataset from a CSV file and store it in a list of lists (or a list of dictionaries, if you're comfortable with dictionaries). Each inner list/dictionary should represent a single person's information.\n",
    "   \n",
    "2. **Data Cleaning**:\n",
    "   - Write a function to clean the dataset (e.g., replace missing values represented by \"?\" with `None` or a relevant placeholder).\n",
    "\n",
    "3. **Basic Analysis**:\n",
    "   - Write functions to calculate:\n",
    "     - The average age of individuals in the dataset.\n",
    "     - The distribution of individuals by education level (i.e., the count of individuals for each education level).\n",
    "\n",
    "4. **Income Level Analysis**:\n",
    "   - Write a function to determine the percentage of individuals making more than $50,000 a year, grouped by education level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183b2c0",
   "metadata": {},
   "source": [
    "\n",
    "#### Dataset Details\n",
    "\n",
    "- You can download a simplified version of the dataset, which includes a subset of the columns: [Download Sample Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)\n",
    "\n",
    "- Consider using a smaller sample of the dataset for ease of testing.\n",
    "\n",
    "#### Sample Dataset Columns\n",
    "\n",
    "For simplicity, use these columns: Age, Workclass, Education, Occupation, and Income.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae33d2d",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27f3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to read the dataset from a CSV file and store it in a list of dictionaries\n",
    "def read_dataset(filename):\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        dataset = [row for row in reader]\n",
    "    return dataset\n",
    "\n",
    "# Function to clean the dataset\n",
    "def clean_dataset(dataset):\n",
    "    for row in dataset:\n",
    "        # Replace missing values represented by \"?\" with None\n",
    "        for key, value in row.items():\n",
    "            if value == \"?\":\n",
    "                row[key] = None\n",
    "    return dataset\n",
    "\n",
    "# Function to calculate the average age of individuals in the dataset\n",
    "def calculate_average_age(dataset):\n",
    "    ages = [int(row['age']) for row in dataset if row['age'] is not None]\n",
    "    if len(ages) == 0:\n",
    "        return None\n",
    "    return sum(ages) / len(ages)\n",
    "\n",
    "# Function to calculate the distribution of individuals by education level\n",
    "def calculate_education_distribution(dataset):\n",
    "    education_levels = {}\n",
    "    for row in dataset:\n",
    "        education_level = row['education']\n",
    "        if education_level not in education_levels:\n",
    "            education_levels[education_level] = 0\n",
    "        education_levels[education_level] += 1\n",
    "    return education_levels\n",
    "\n",
    "# Function to determine the percentage of individuals making more than $50,000 a year, grouped by education level\n",
    "def calculate_income_percentage(dataset):\n",
    "    total_count = len(dataset)\n",
    "    high_income_count_by_education = {}\n",
    "    for row in dataset:\n",
    "        education_level = row['education']\n",
    "        income = row['income']\n",
    "        if income == '>50K':\n",
    "            if education_level not in high_income_count_by_education:\n",
    "                high_income_count_by_education[education_level] = 0\n",
    "            high_income_count_by_education[education_level] += 1\n",
    "    \n",
    "    income_percentage_by_education = {}\n",
    "    for education_level, high_income_count in high_income_count_by_education.items():\n",
    "        total_count_for_education = sum(1 for row in dataset if row['education'] == education_level)\n",
    "        percentage = (high_income_count / total_count_for_education) * 100\n",
    "        income_percentage_by_education[education_level] = percentage\n",
    "    \n",
    "    return income_percentage_by_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc874392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age: 38.64358543876172\n",
      "Education Distribution:\n",
      "11th: 1812\n",
      "HS-grad: 15784\n",
      "Assoc-acdm: 1601\n",
      "Some-college: 10878\n",
      "10th: 1389\n",
      "Prof-school: 834\n",
      "7th-8th: 955\n",
      "Bachelors: 8025\n",
      "Masters: 2657\n",
      "Doctorate: 594\n",
      "5th-6th: 509\n",
      "Assoc-voc: 2061\n",
      "9th: 756\n",
      "12th: 657\n",
      "1st-4th: 247\n",
      "Preschool: 83\n",
      "\n",
      "Income Percentage by Education Level:\n",
      "Assoc-acdm: 25.79637726420987%\n",
      "Some-college: 18.964883250597538%\n",
      "Prof-school: 73.98081534772182%\n",
      "HS-grad: 15.857830714647744%\n",
      "Masters: 54.91155438464433%\n",
      "Doctorate: 72.55892255892256%\n",
      "Bachelors: 41.283489096573206%\n",
      "Assoc-voc: 25.327510917030565%\n",
      "9th: 5.423280423280423%\n",
      "10th: 6.263498920086392%\n",
      "7th-8th: 6.492146596858639%\n",
      "11th: 5.077262693156733%\n",
      "5th-6th: 5.304518664047151%\n",
      "1st-4th: 3.2388663967611335%\n",
      "12th: 7.30593607305936%\n",
      "Preschool: 1.2048192771084338%\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    filename = 'adult.csv'\n",
    "    dataset = read_dataset(filename)\n",
    "    cleaned_dataset = clean_dataset(dataset)\n",
    "    \n",
    "    # Basic Analysis\n",
    "    average_age = calculate_average_age(cleaned_dataset)\n",
    "    education_distribution = calculate_education_distribution(cleaned_dataset)\n",
    "    \n",
    "    print(\"Average Age:\", average_age)\n",
    "    print(\"Education Distribution:\")\n",
    "    for education, count in education_distribution.items():\n",
    "        print(f\"{education}: {count}\")\n",
    "    \n",
    "    # Income Level Analysis\n",
    "    income_percentage = calculate_income_percentage(cleaned_dataset)\n",
    "    print(\"\\nIncome Percentage by Education Level:\")\n",
    "    for education, percentage in income_percentage.items():\n",
    "        print(f\"{education}: {percentage}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02b78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad685276",
   "metadata": {},
   "source": [
    "## Additional Task\n",
    "\n",
    "- Review the provided Python script, understand its functionality, and run it with a dataset of your choice that matches the expected format.\n",
    "\n",
    "- Analysis: Identify any potential issues or limitations with the script that could arise with different datasets.\n",
    "\n",
    "- Documentation: For each function you modify or add, include a docstring explaining its purpose, inputs, and outputs. Additionally, comment on your reasoning for any significant changes or decisions you made in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdfc6d0",
   "metadata": {},
   "source": [
    "## Homework2:Text Analysis with \"The Adventures of Sherlock Holmes\"\n",
    "\n",
    "Objective: Write Python functions to load and analyze text data from \"The Adventures of Sherlock Holmes\" by Arthur Conan Doyle. The analysis will include counting words, finding unique words, and identifying the most common words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf4784",
   "metadata": {},
   "source": [
    "### Dataset Details\n",
    "\n",
    "Text Source: Project Gutenberg's \"The Adventures of Sherlock Holmes\"\n",
    "\n",
    "Direct Download URL: https://www.gutenberg.org/files/1661/1661-0.txt\n",
    "\n",
    "You might need to download the text file manually or programmatically download it within your Python script (consider using requests library for downloading if going the programmatic route, but remember to respect robots.txt and usage policies of websites)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119c28c",
   "metadata": {},
   "source": [
    "# Task Overview\n",
    "\n",
    "**Data Loading:**\n",
    "\n",
    "- Write a function to read the entire text of \"The Adventures of Sherlock Holmes\" into a single string.\n",
    "\n",
    "**Data Cleaning and Preprocessing:**\n",
    "\n",
    "- Write a function to remove punctuation and make all words lowercase to ensure accurate word counting.\n",
    "\n",
    "**Word Frequency Analysis:**\n",
    "\n",
    "- Write a function to count how often each word appears in the text and identify the top 10 most frequent words.\n",
    "\n",
    "**Unique Words:**\n",
    "- Write a function to find all unique words in the text.\n",
    "\n",
    "**Explain Each Step:**\n",
    "\n",
    "- For each function written, include a docstring that explains what the function does, its inputs, and its outputs. Additionally, add comments throughout your code to explain each step of your logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f04bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import requests\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825089cb",
   "metadata": {},
   "source": [
    "#### Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d8a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(url):\n",
    "    \"\"\"\n",
    "    Load the text of \"The Adventures of Sherlock Holmes\" from the provided URL.\n",
    "    \n",
    "    Args:\n",
    "    url (str): The URL from which to download the text.\n",
    "    \n",
    "    Returns:\n",
    "    str: The entire text of \"The Adventures of Sherlock Holmes\" as a single string.\n",
    "    \"\"\"\n",
    "    # Download the HTML content from the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Use BeautifulSoup to parse the HTML\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Get all text from the webpage\n",
    "    text = soup.text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df40f5f",
   "metadata": {},
   "source": [
    "#### 1) Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24d1d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the text by removing punctuation and converting all words to lowercase.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to clean.\n",
    "    \n",
    "    Returns:\n",
    "    str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Remove punctuation\n",
    "    cleaned_text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Convert all words to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ce22a",
   "metadata": {},
   "source": [
    "##### 2) Word Frequency Analysis\n",
    "This function counts the frequency of each word in the text and identifies the top 10 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80b6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(text):\n",
    "    \"\"\"\n",
    "    Count how often each word appears in the text and identify the top 10 most frequent words.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of tuples containing the top 10 most frequent words and their frequencies.\n",
    "    \"\"\"\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the top 10 most frequent words\n",
    "    top_10_words = word_counts.most_common(10)\n",
    "    \n",
    "    return top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60b0fc",
   "metadata": {},
   "source": [
    "##### 3) Unique Words\n",
    "This function finds all unique words in the cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53724a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(text):\n",
    "    \"\"\"\n",
    "    Find all unique words in the text.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    set: A set containing all unique words in the text.\n",
    "    \"\"\"\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Get the unique words using set\n",
    "    unique_words_set = set(words)\n",
    "    \n",
    "    return unique_words_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fe124",
   "metadata": {},
   "source": [
    "##### The main function to perform all the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962bdd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words:\n",
      "the: 5717\n",
      "and: 2936\n",
      "of: 2765\n",
      "to: 2735\n",
      "a: 2652\n",
      "i: 2600\n",
      "in: 1789\n",
      "that: 1655\n",
      "it: 1477\n",
      "he: 1417\n",
      "\n",
      "Number of unique words: 10398\n"
     ]
    }
   ],
   "source": [
    "# Main function to perform the analysis\n",
    "def main():\n",
    "    # URL of the text\n",
    "    url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
    "    \n",
    "    # Load the text\n",
    "    text = load_text(url)\n",
    "    \n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Word frequency analysis\n",
    "    top_10_words = word_frequency(cleaned_text)\n",
    "    print(\"Top 10 most frequent words:\")\n",
    "    for word, count in top_10_words:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    # Unique words\n",
    "    unique_words_set = unique_words(cleaned_text)\n",
    "    print(\"\\nNumber of unique words:\", len(unique_words_set))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5802fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3239eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79670f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a7c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
