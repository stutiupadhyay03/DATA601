{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555d0ff1",
   "metadata": {},
   "source": [
    "##### Name: Stuti Upadhyay\n",
    "##### Campus ID: XT81177\n",
    "##### Instructor: Chalachew Jemberie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476b59b",
   "metadata": {},
   "source": [
    "### Question 1: Conceptual Understanding of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588d5b3",
   "metadata": {},
   "source": [
    "**Explain the main purpose of Principal Component Analysis (PCA) in data science.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c36e32",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a widely used technique in data science and machine learning for dimensionality reduction. Its main purpose is to simplify the complexity of high-dimensional datasets while preserving most of the important information. \n",
    "\n",
    "Some important areas it usually focuses on are:\n",
    "\n",
    "1. **Dimensionality Reduction**: Simplifying complex datasets by reducing the number of features while preserving important information.\n",
    "\n",
    "2. **Feature Extraction**: Identifying patterns in data and creating new, more interpretable features.\n",
    "\n",
    "3. **Visualization**: Helping visualize high-dimensional data in two or three dimensions.\n",
    "\n",
    "4. **Noise Reduction**: Filtering out irrelevant variations and focusing on significant patterns.\n",
    "\n",
    "5. **Preprocessing**: Preparing data for machine learning models by reducing complexity and speeding up training.\n",
    "\n",
    "In conclusion one can say PCA simplifies data, extracts important features, and improves the efficiency of machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e68945",
   "metadata": {},
   "source": [
    "### Question 2: Implementing PCA with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b61d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (150, 8)\n",
      "First few rows of the dataset:\n",
      "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n",
      "  0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152 0.79172504 0.52889492 0.56804456 0.92559664\n",
      "  0.07103606 0.0871293 ]\n",
      " [0.0202184  0.83261985 0.77815675 0.87001215 0.97861834 0.79915856\n",
      "  0.46147936 0.78052918]\n",
      " [0.11827443 0.63992102 0.14335329 0.94466892 0.52184832 0.41466194\n",
      "  0.26455561 0.77423369]\n",
      " [0.45615033 0.56843395 0.0187898  0.6176355  0.61209572 0.616934\n",
      "  0.94374808 0.6818203 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a NumPy array with 100 samples and 3 features\n",
    "np.random.seed(0)  # for reproducibility\n",
    "num_samples = 150\n",
    "num_features = 8\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "\n",
    "# Displaying the shape of the dataset\n",
    "print(\"Shape of the dataset:\", X.shape)\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(X[:5])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform the data\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9363f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52214033 -0.50491204]\n",
      " [ 0.44705823  1.15000831]\n",
      " [-1.73183426  1.53736106]\n",
      " [-2.06106183  0.10992432]\n",
      " [-1.16592421 -0.37320544]\n",
      " [ 0.68378907  1.53810295]\n",
      " [ 0.74020691  1.7078253 ]\n",
      " [ 1.59518741 -0.9576709 ]\n",
      " [ 1.491938    0.17613618]\n",
      " [ 2.83272114 -0.08525213]\n",
      " [-0.43793631  0.65804093]\n",
      " [-0.39947938  0.45845432]\n",
      " [ 1.14467502 -1.3395826 ]\n",
      " [-1.60315537 -0.6015305 ]\n",
      " [ 0.56300167 -0.15843926]\n",
      " [ 0.48582654  0.56749147]\n",
      " [ 0.66039362 -1.55895731]\n",
      " [ 0.24003777  0.30436742]\n",
      " [-2.1852382   0.48312561]\n",
      " [-1.32564617  1.91171616]\n",
      " [-0.79069975  1.84742563]\n",
      " [ 2.20075227 -1.34393406]\n",
      " [ 1.08707625  0.33602611]\n",
      " [ 1.16015681  0.7789288 ]\n",
      " [ 0.34220363  0.4882295 ]\n",
      " [ 1.02495679 -1.12781008]\n",
      " [ 1.28106953  0.69059098]\n",
      " [-1.91320626  0.23669777]\n",
      " [ 0.20995861  2.70481678]\n",
      " [-0.65610613 -0.7829047 ]\n",
      " [ 1.5137695   0.2490209 ]\n",
      " [-1.37771513  1.2812136 ]\n",
      " [ 1.09327855 -1.05047758]\n",
      " [-0.27910134 -2.00613966]\n",
      " [-2.09394604  0.98448349]\n",
      " [ 1.63833646 -0.47663902]\n",
      " [ 1.29434953  1.16191301]\n",
      " [-0.7441487   2.68123904]\n",
      " [ 1.28918204  0.30337644]\n",
      " [-0.42569894 -1.01627026]\n",
      " [-0.91363903 -1.34318364]\n",
      " [-1.90299024 -1.67135406]\n",
      " [ 1.03046306  0.38424088]\n",
      " [ 0.29114581  0.49825234]\n",
      " [-0.29257236 -1.4348759 ]\n",
      " [ 0.06820573  1.45872171]\n",
      " [ 1.22846151  1.46834917]\n",
      " [ 0.59220872  0.44165448]\n",
      " [ 1.71691165  1.05187852]\n",
      " [-1.2882713   1.09039871]\n",
      " [-1.0117642   1.91788288]\n",
      " [-0.06184035 -1.06673765]\n",
      " [-2.13991745  1.82521099]\n",
      " [ 1.64816957  0.42145252]\n",
      " [ 0.34481832  0.27526825]\n",
      " [ 1.12376958 -1.37238661]\n",
      " [ 0.92413407 -0.84736864]\n",
      " [-0.41933136 -1.58671089]\n",
      " [-0.36532622 -0.34397124]\n",
      " [-0.07049926  0.64556359]\n",
      " [-1.8104858  -1.25862162]\n",
      " [ 0.64754346  0.85250759]\n",
      " [-0.56036169 -1.086743  ]\n",
      " [ 1.24636388  0.71518381]\n",
      " [ 0.15758131 -1.65035609]\n",
      " [-1.30898496 -2.31369275]\n",
      " [-0.43377285  1.2832975 ]\n",
      " [-0.6850807  -1.19283357]\n",
      " [ 1.00419066 -0.61020537]\n",
      " [ 0.62029836 -1.38139403]\n",
      " [-1.21803018 -0.99724511]\n",
      " [ 2.64284776 -0.61639832]\n",
      " [-1.01231486  0.75539219]\n",
      " [-0.8137386  -2.05220361]\n",
      " [-1.40787318 -1.2275928 ]\n",
      " [ 0.57706421  1.01317324]\n",
      " [ 0.76370468  1.34968247]\n",
      " [-1.50197469 -0.83859536]\n",
      " [ 1.60474267  0.31361728]\n",
      " [-0.08011064 -1.66335863]\n",
      " [ 2.05631575 -0.76032985]\n",
      " [ 1.37802258 -1.16300014]\n",
      " [-1.71700834  0.41056564]\n",
      " [ 0.02531092  0.78909259]\n",
      " [-0.04188704  0.53916204]\n",
      " [-1.58246405 -1.44446137]\n",
      " [ 2.07936383 -0.49684958]\n",
      " [-0.5613974   0.32163828]\n",
      " [-1.10522252 -0.6873471 ]\n",
      " [-0.04226058 -0.7126885 ]\n",
      " [-1.89974507 -0.82144162]\n",
      " [ 0.7135035  -1.13578783]\n",
      " [-1.03642215  0.58651252]\n",
      " [-0.09307695  0.62599645]\n",
      " [ 0.62843241 -0.44411584]\n",
      " [ 0.22037769  0.59186837]\n",
      " [ 2.46818938 -0.97204418]\n",
      " [-0.40080805 -1.80194187]\n",
      " [ 0.62019734 -0.12990519]\n",
      " [ 0.19168152 -0.68277757]\n",
      " [-0.63305123  1.14530392]\n",
      " [-0.24302354  0.65485627]\n",
      " [ 1.02671247  0.57605772]\n",
      " [-0.2287435   1.63189027]\n",
      " [ 1.30089878  0.4405209 ]\n",
      " [-1.90374555 -0.22872103]\n",
      " [-0.5060503  -1.70427394]\n",
      " [-1.4901114   2.02516414]\n",
      " [ 0.77139435  1.41939083]\n",
      " [-0.07148882 -1.31744937]\n",
      " [-0.04223228 -0.57206993]\n",
      " [-0.55373093  0.4645958 ]\n",
      " [ 1.19124595  1.52660074]\n",
      " [ 1.81393691 -0.49127934]\n",
      " [ 1.45603078 -1.16396959]\n",
      " [-0.50158299  0.77613696]\n",
      " [ 1.90955746 -1.6614672 ]\n",
      " [-1.2196071  -1.22142777]\n",
      " [-0.92518229  0.10019801]\n",
      " [-1.16008583 -1.05719808]\n",
      " [-0.81596755 -0.60236699]\n",
      " [ 0.86230085  1.79536933]\n",
      " [-1.04352604  0.56452437]\n",
      " [ 0.02920381 -0.006672  ]\n",
      " [-0.54904151  0.57835309]\n",
      " [-0.70311851 -0.60952017]\n",
      " [ 0.48815206  0.87185336]\n",
      " [-1.1439227  -1.75605789]\n",
      " [ 2.16815131  1.84575227]\n",
      " [ 1.63432464 -0.20336433]\n",
      " [-1.09683267 -1.87882234]\n",
      " [ 1.49673054  0.48663154]\n",
      " [ 0.44754899  2.22370378]\n",
      " [-1.71758261 -0.23917441]\n",
      " [-0.43244894 -0.50723666]\n",
      " [-1.98828224  1.32396356]\n",
      " [-0.10474176  0.56560809]\n",
      " [-1.71889329  0.37062236]\n",
      " [ 1.64999088  0.31840101]\n",
      " [ 0.544348   -1.50585557]\n",
      " [ 0.69601039  0.37410864]\n",
      " [-0.16300763  1.53359193]\n",
      " [-0.11337516 -1.14842752]\n",
      " [-1.74721844  0.22646531]\n",
      " [-1.84002688 -0.11332742]\n",
      " [ 0.358934   -1.86287538]\n",
      " [ 0.35597484 -0.58074787]\n",
      " [ 0.27908858  0.65143346]\n",
      " [-1.51732362  0.2577631 ]\n",
      " [-0.44832513  0.902609  ]]\n"
     ]
    }
   ],
   "source": [
    "#Fill in the missing code to perform PCA on the scaled dataset `X_scaled` to reduce its dimensionality to 2 components.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Assuming X_scaled is pre-defined and scaled\n",
    "# MISSING CODE HERE: Instantiate PCA with 2 components and fit_transform X_scaled\n",
    "#pca = PCA(n_components=__)\n",
    "#X_pca = pca.fit_transform(___)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33435d30",
   "metadata": {},
   "source": [
    "### Question 3: Understanding Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae48b4e",
   "metadata": {},
   "source": [
    "**What do the mean and standard deviation represent in a dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4da1c",
   "metadata": {},
   "source": [
    "In a dataset, the mean and standard deviation are two descriptive statistics that provide information about the distribution of the data:\n",
    "\n",
    "1. **Mean**: The mean, also known as the average will usually represents the central tendency of the data. It is calculated by summing up all the values in the dataset and dividing by the total number of values. The mean indicates where the data tends to center or focus around.\n",
    "\n",
    "2. **Standard Deviation**: The standard deviation measures the dispersion or spread of the data points around the mean. It indicates how much the data deviates from the mean on average. A smaller standard deviation suggests that the data points are close to the mean, while a larger standard deviation suggests that the data points are more spread out.\n",
    "\n",
    "Together, the mean and standard deviation will often provide valuable insights into the central tendency and variability of the dataset, helping analysts understand the overall distribution of the data and make informed decisions during analyzing a data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2352b1",
   "metadata": {},
   "source": [
    "### Question 4: Calculating Descriptive Statistics in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeb566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5.5, Standard Deviation: 2.8722813232690143\n"
     ]
    }
   ],
   "source": [
    "#Calculate the mean and standard deviation of the given numpy array `data`. Fill in the missing code.\n",
    "\n",
    "import numpy as np\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# MISSING CODE HERE: Calculate the mean and standard deviation\n",
    "#mean = np.___(data)\n",
    "#std_dev = np.___(data)\n",
    "# Calculating the mean and standard deviation\n",
    "mean = np.mean(data)\n",
    "std_dev = np.std(data)\n",
    "print(f\"Mean: {mean}, Standard Deviation: {std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52059cf2",
   "metadata": {},
   "source": [
    "### Question 5: Conceptual on Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622c55d",
   "metadata": {},
   "source": [
    "**Describe the Central Limit Theorem and its significance in statistics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aba0c7",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is one of the most fundamental aspect of statistics that states the following:\n",
    "\n",
    "**\"Given a sufficiently large sample size drawn from any population with a finite mean and variance, the sampling distribution of the sample mean will be approximately normally distributed, regardless of the shape of the original population distribution. Moreover, as the sample size increases, the sampling distribution of the sample mean approaches a normal distribution even if the population distribution is not normal.\"**\n",
    "\n",
    "The significance of the Central Limit Theorem lies in its wide-ranging applications and implications in statistics:\n",
    "\n",
    "1. **Normal Approximation**: The CLT allows statisticians to approximate the sampling distribution of the sample mean using a normal distribution, which simplifies calculations and enables the use of standard statistical techniques.\n",
    "\n",
    "2. **Inference and Estimation**: It provides the theoretical foundation for many statistical methods, such as confidence intervals and hypothesis testing. These methods rely on the assumption of normality for sample means, which is justified by the CLT.\n",
    "\n",
    "3. **Population Inference**: Even when the population distribution is unknown or non-normal, the CLT allows us to make inferences about population parameters based on the sample mean, assuming the sample size is sufficiently large.\n",
    "\n",
    "4. **Quality Control and Process Improvement**: In fields like manufacturing and quality control, where sample means are often used to monitor processes and make decisions, the CLT provides assurance that the distribution of sample means will be approximately normal, facilitating process monitoring and improvement efforts.\n",
    "\n",
    "5. **Sampling Design**: The CLT guides sampling design by indicating that even if the population distribution is not known, a large enough sample size will result in a sampling distribution that is approximately normal, making it easier to draw valid conclusions from the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4760ad8",
   "metadata": {},
   "source": [
    "### Question 6: Demonstration of the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc6d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Generate a sample of size 30 from a population `population_data` 1000 times, calculate the sample means, and plot their distribution. Complete the missing code.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "population_data = np.random.exponential(scale=5.0, size=10000)\n",
    "sample_means = []\n",
    "for _ in range(1000):\n",
    "    sample = np.random.choice(population_data, size=30)\n",
    "    # MISSING CODE HERE: Append the mean of the sample to sample_means\n",
    "    #sample_means.append(np.___(sample))\n",
    "    sample_means.append(np.mean(sample))\n",
    "# Plot the distribution of sample_means\n",
    "plt.hist(sample_means, bins=30, edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adefaaa",
   "metadata": {},
   "source": [
    "### Question 7: Interpretation of p-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166ef7e",
   "metadata": {},
   "source": [
    "**What does a p-value less than 0.05 typically indicate about the null hypothesis in a hypothesis testing scenario?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dbdd37",
   "metadata": {},
   "source": [
    "In hypothesis testing, a p-value less than 0.05 typically indicates that there is sufficient evidence to reject the null hypothesis at the 5% significance level. In other words one can that it suggests that the observed data is unlikely to have occurred if the null hypothesis were true. Therefore, a p-value less than 0.05 is often interpreted as evidence in favor of the alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7e034",
   "metadata": {},
   "source": [
    "### Question 8: Confidence Interval Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9071164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (1.5995630967087155, 8.400436903291284)\n"
     ]
    }
   ],
   "source": [
    "# Given a dataset `sample_data`, calculate the 95% confidence interval for the mean. Fill in the missing parts.\n",
    "from scipy import stats\n",
    "sample_data = np.array([2, 3, 5, 6, 9])\n",
    "# MISSING CODE HERE: Calculate the 95% confidence interval\n",
    "confidence_interval = stats.t.interval(0.95, len(sample_data)-1, loc=np.mean(sample_data), scale=stats.sem(sample_data))\n",
    "print(f\"95% Confidence Interval: {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1972f61",
   "metadata": {},
   "source": [
    "### Question 9: Bayesian Statistics Concept\n",
    "\n",
    "**Explain how Bayesian statistics differs from frequentist statistics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9844261",
   "metadata": {},
   "source": [
    "Bayesian statistics and frequentist statistics differ singnificantly with their approach to probability and inference:\n",
    "\n",
    "1. **Probability Interpretation**:\n",
    "   - Frequentist: Probability represents long-run frequencies of events in repeated experiments. \n",
    "   - Example: If you toss a fair coin many times, the proportion of times it lands heads approximates the true probability of getting heads.\n",
    "   - Bayesian: Probability expresses a degree of belief or uncertainty about an event. \n",
    "   - Example: If you believe there's a 70% chance of rain tomorrow based on weather patterns and update this belief with current weather observations, you're using Bayesian probability to adjust your degree of belief.\n",
    "\n",
    "2. **Parameter Estimation**:\n",
    "   - Frequentist: Estimates parameters based on sample data, treating them as fixed but unknown values. \n",
    "   - Example: Estimating the average height of students in a class based on a sample mean and standard deviation.\n",
    "   - Bayesian: Incorporates prior beliefs about parameters and updates them using observed data to obtain posterior distributions. \n",
    "   - Example:Estimating the effectiveness of a new drug by combining prior knowledge (e.g., from previous studies) with current clinical trial data to update beliefs about its efficacy.\n",
    "\n",
    "3. **Hypothesis Testing**:\n",
    "   - Frequentist: Focuses on null hypothesis significance testing, where p-values indicate the strength of evidence against the null hypothesis. \n",
    "   - Example: Conducting a hypothesis test to determine whether a new teaching method improves student performance, where the p-value indicates the strength of evidence against the null hypothesis.\n",
    "   - Bayesian: Evaluates hypotheses by comparing posterior probabilities, integrating prior beliefs with observed data. \n",
    "   - Example: Evaluating whether a new marketing strategy is more effective than the existing one by comparing the posterior probabilities of different hypotheses, integrating prior beliefs about their effectiveness with observed sales data.\n",
    "\n",
    "Hence one can infer that, frequentist statistics relies solely on observed data, while Bayesian statistics incorporates prior knowledge and updates beliefs based on both prior information and observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3679f1e",
   "metadata": {},
   "source": [
    "### Question 10: Solving Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d058f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [0.81818182 1.27272727]\n"
     ]
    }
   ],
   "source": [
    "#Solve the system of linear equations given by 3x + 2y = 5 and 4x - y = 2. Fill in the blanks.\n",
    "\n",
    "A = np.array([[3, 2], [4, -1]])\n",
    "B = np.array([5, 2])\n",
    "# MISSING CODE HERE: Solve the system of equations and print the solution\n",
    "solution = np.linalg.solve(A,B)\n",
    "print(f\"Solution: {solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e5c33",
   "metadata": {},
   "source": [
    "### Question 11: Conceptual Understanding of Eigenvalues and Eigenvectors\n",
    "**Explain what eigenvalues and eigenvectors represent in the context of linear transformations and how they are used in data science.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36bd70",
   "metadata": {},
   "source": [
    "When we take lineat transformations in context, eigenvalues and eigenvectors are one of those subject matters that used to understand how matrices act on vectors. Following are the more accurate definition of both eigenvalues and eigenvectors.\n",
    "\n",
    "1. **Eigenvalues**: Eigenvalues are scalar values that represent the factor by which an eigenvector is scaled during a linear transformation. In other words, when a matrix is applied to an eigenvector, the eigenvector only changes in magnitude, not direction. The eigenvalue indicates how much the eigenvector is stretched or compressed by the transformation.\n",
    "\n",
    "2. **Eigenvectors**: Eigenvectors are non-zero vectors that remain in the same direction after a linear transformation, albeit possibly with a different magnitude. They represent the directions along which the linear transformation has a particularly simple effect. Each eigenvector corresponds to one or more eigenvalues.\n",
    "\n",
    "In data science, eigenvalues and eigenvectors are used in various ways, including:\n",
    "\n",
    "- **Dimensionality Reduction**: In techniques like Principal Component Analysis (PCA), eigenvectors and eigenvalues are used to transform the original data into a new coordinate system, where the axes represent the directions of maximum variance in the data.\n",
    "\n",
    "- **Feature Extraction**: Eigenvectors provide a way to extract important features from high-dimensional datasets. By selecting the eigenvectors corresponding to the largest eigenvalues, one can identify the most significant directions of variation in the data, which can then be used as features for modeling.\n",
    "\n",
    "- **Image Compression**: In applications such as image processing, eigenvalues and eigenvectors are used in techniques like Singular Value Decomposition (SVD) to compress images while preserving important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8db26",
   "metadata": {},
   "source": [
    "### Question 12: Computing Eigenvalues and Eigenvectors in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fa9108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [5. 2.]\n",
      "Eigenvectors:\n",
      "[[ 0.89442719 -0.70710678]\n",
      " [ 0.4472136   0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "#Given a square matrix `A`, fill in the missing code to compute its eigenvalues and eigenvectors using NumPy.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[4, 2], [1, 3]])\n",
    "# MISSING CODE: Compute the eigenvalues and eigenvectors of A\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "print(f\"Eigenvalues: {eigenvalues}\\nEigenvectors:\\n{eigenvectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc16c5",
   "metadata": {},
   "source": [
    "### Question 13: The Role of PCA in Machine Learning\n",
    "\n",
    "**Discuss the role of Principal Component Analysis (PCA) in machine learning, specifically in the context of feature selection and dimensionality reduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63429a",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) plays a crucial role in machine learning, particularly in the areas where feature selection and dimensionality reduction are important components of the project. Following is the more in depth explanation of how PCA contributes to Feature Selection and Dimensionality Reduction. \n",
    "\n",
    "1. **Feature Selection**:\n",
    "   - PCA helps identify the most informative features in a dataset by transforming the original features into a new set of orthogonal (uncorrelated) features called principal components.\n",
    "   - These principal components are ordered by the amount of variance they explain in the data. Features corresponding to the top principal components contribute the most to the overall variance, indicating their importance.\n",
    "   - By selecting a subset of the top principal components, PCA effectively performs feature selection by retaining only the most relevant and informative features while discarding redundant or less important ones.\n",
    "   - This feature selection aspect of PCA is particularly useful for reducing overfitting, improving model interpretability, and speeding up computation in machine learning algorithms.\n",
    "\n",
    "2. **Dimensionality Reduction**:\n",
    "   - In high-dimensional datasets where the number of features exceeds the number of observations or where there is multicollinearity among features, PCA reduces the dimensionality by transforming the data into a lower-dimensional space.\n",
    "   - PCA achieves dimensionality reduction by projecting the original data onto a lower-dimensional subspace spanned by a subset of the principal components.\n",
    "   - By retaining only the top principal components that capture the most variance in the data, PCA effectively compresses the information while minimizing the loss of important patterns or structures.\n",
    "   - Dimensionality reduction with PCA can lead to simpler and more efficient models, faster training times, and improved generalization performance by reducing the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19b97d",
   "metadata": {},
   "source": [
    "\n",
    "### Question 14: Implementing PCA on a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b39c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (200, 10)\n",
      "First few rows of the dataset:\n",
      "[[0.98901151 0.54954473 0.2814473  0.07728957 0.4444695  0.47280797\n",
      "  0.048522   0.16332445 0.11595071 0.62739168]\n",
      " [0.85618205 0.65010242 0.99072168 0.47035075 0.61829448 0.28266721\n",
      "  0.97600332 0.673068   0.44053089 0.28968734]\n",
      " [0.50969968 0.1124609  0.22695479 0.4785523  0.24275816 0.38798252\n",
      "  0.81887343 0.07454079 0.92314954 0.22489608]\n",
      " [0.70637148 0.11056546 0.60100412 0.40679254 0.83682945 0.25003043\n",
      "  0.45773799 0.5574327  0.2519502  0.11024132]\n",
      " [0.7266372  0.31007394 0.82575397 0.45166653 0.09413893 0.88720324\n",
      "  0.74175413 0.12193228 0.85586907 0.06693827]]\n"
     ]
    }
   ],
   "source": [
    "#Creeating a sample dataset X with multiple features\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(45)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 200\n",
    "\n",
    "# Number of features\n",
    "num_features = 10\n",
    "\n",
    "# Generate the dataset\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(\"Shape of the dataset:\", X.shape)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a91503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.72592891e-01  1.28562065e+00]\n",
      " [-9.38776653e-01 -7.18600152e-01]\n",
      " [-1.85966161e+00  1.28531404e+00]\n",
      " [-1.90595342e-01 -8.25726501e-01]\n",
      " [-2.85815725e+00  1.03066193e+00]\n",
      " [-1.88527365e+00 -2.18189304e+00]\n",
      " [-3.31179236e-01 -4.80780859e-01]\n",
      " [-3.04635287e-01 -1.04396499e+00]\n",
      " [ 1.07281979e+00 -2.04590471e+00]\n",
      " [-1.68754378e+00  4.17717643e-02]\n",
      " [-2.53737062e+00 -2.17512044e-01]\n",
      " [-5.71023870e-02  1.66636977e+00]\n",
      " [-1.57176333e-01  4.96005893e-01]\n",
      " [-8.42238022e-01  2.32325633e-01]\n",
      " [-3.31932571e-01 -1.28710048e+00]\n",
      " [-8.07111609e-01  7.48228242e-02]\n",
      " [-1.84966337e-02  3.68757028e-01]\n",
      " [ 1.53843611e+00  7.43525540e-01]\n",
      " [ 2.23729902e+00  6.84911417e-01]\n",
      " [ 2.27240439e+00 -1.58379550e+00]\n",
      " [-2.41197911e-01 -2.72978199e-01]\n",
      " [ 6.23937841e-01  1.08908140e+00]\n",
      " [-7.82576150e-01 -1.27647065e-01]\n",
      " [ 6.99098699e-02  9.33484719e-01]\n",
      " [-1.50967257e-01 -2.52509166e-01]\n",
      " [-1.26233263e+00 -1.75382612e+00]\n",
      " [-1.32292158e+00 -7.84675185e-01]\n",
      " [-2.81847062e-01 -1.25136111e+00]\n",
      " [ 6.60419051e-01 -3.33854576e-01]\n",
      " [ 1.54471426e+00  1.88227062e+00]\n",
      " [-9.48344744e-01  8.34278389e-01]\n",
      " [ 4.19778393e-02  8.02809786e-01]\n",
      " [-1.22143254e+00 -1.13069890e+00]\n",
      " [ 2.33258692e-01  1.17930023e+00]\n",
      " [ 1.05148023e+00  4.30561848e-01]\n",
      " [ 7.40857427e-01  3.18729059e-01]\n",
      " [-1.97507174e-01  5.78209574e-01]\n",
      " [ 6.16263171e-02  2.76852532e-01]\n",
      " [ 2.54932837e+00  1.29645175e+00]\n",
      " [ 1.06209993e-01  2.10597082e-01]\n",
      " [-9.81068386e-01 -7.61350207e-01]\n",
      " [-1.90611861e-01 -1.30701986e+00]\n",
      " [-4.75534952e-01  1.88508192e+00]\n",
      " [-8.31620700e-01 -7.53608577e-01]\n",
      " [-1.09553382e+00 -1.40123352e+00]\n",
      " [ 3.50530428e-01 -1.36600902e+00]\n",
      " [ 1.06079182e+00  4.85142740e-02]\n",
      " [-1.27346093e+00 -1.65912976e+00]\n",
      " [-1.37447719e+00  9.07895359e-01]\n",
      " [-2.18629120e-01  2.22488046e+00]\n",
      " [-2.04376454e-01  1.48571628e+00]\n",
      " [ 1.48089224e+00 -9.05917718e-01]\n",
      " [-1.04226260e+00 -1.02996946e+00]\n",
      " [ 8.38191648e-01 -1.53392612e+00]\n",
      " [-1.86119253e-01  8.31036199e-01]\n",
      " [-1.06306002e-01 -8.66001149e-01]\n",
      " [-4.43701489e-02  3.49007016e-02]\n",
      " [ 1.75312300e+00 -5.97883554e-01]\n",
      " [ 5.94483139e-01  1.35924909e+00]\n",
      " [ 3.91649821e-01 -1.25093490e+00]\n",
      " [ 1.96203969e+00 -2.49025342e-01]\n",
      " [-1.88647952e+00  9.24399122e-01]\n",
      " [ 2.39792429e+00 -3.92806624e-01]\n",
      " [-2.22046579e-01  6.34040132e-01]\n",
      " [ 1.00778662e+00 -1.26569036e+00]\n",
      " [-9.66603055e-01  1.40365990e+00]\n",
      " [ 8.34024299e-01 -5.30059428e-01]\n",
      " [-1.95484221e+00 -6.04059910e-01]\n",
      " [ 1.22680447e+00 -5.70666538e-01]\n",
      " [-4.33975545e-01 -1.67130929e-01]\n",
      " [ 9.57355035e-01  1.16063996e+00]\n",
      " [-1.31082869e+00  4.36721844e-01]\n",
      " [-1.49976138e+00  7.49826575e-01]\n",
      " [-5.15089910e-01  8.77157646e-01]\n",
      " [-3.65654813e-01 -4.46420861e-01]\n",
      " [ 1.43304199e+00  1.60766999e+00]\n",
      " [-3.07344035e-01  2.91697025e-03]\n",
      " [ 8.20222891e-01  8.99786016e-01]\n",
      " [ 1.51376586e-01  8.26897634e-02]\n",
      " [-3.80300986e-02  3.31498306e-01]\n",
      " [-1.31269046e+00  1.09644421e+00]\n",
      " [-8.58139997e-01  4.90650163e-01]\n",
      " [ 3.88022059e-01  1.36063257e-01]\n",
      " [ 6.08817947e-01 -2.85974458e-01]\n",
      " [ 1.51639122e+00  7.39071953e-01]\n",
      " [ 5.44114203e-01 -1.73755835e+00]\n",
      " [ 2.64404759e+00  8.40937440e-01]\n",
      " [-6.99673921e-01  1.84256744e+00]\n",
      " [ 6.46220680e-01 -2.20094269e+00]\n",
      " [-7.73388282e-01  1.50080016e+00]\n",
      " [-1.66198267e-01  8.89167305e-01]\n",
      " [-1.97726768e+00  3.67017555e-02]\n",
      " [ 1.54089612e+00  1.26264023e+00]\n",
      " [ 2.07812811e-01  2.15189288e+00]\n",
      " [ 1.29951898e+00 -1.65134184e+00]\n",
      " [ 2.48863504e-01  1.07019530e+00]\n",
      " [ 2.46806998e+00  1.38620183e+00]\n",
      " [ 6.06899221e-01  5.25820360e-01]\n",
      " [-1.17065040e+00 -8.81489988e-01]\n",
      " [-4.47523724e-01  4.78560625e-01]\n",
      " [ 5.94016806e-02  4.21451990e-01]\n",
      " [-1.56696121e+00  7.37130073e-01]\n",
      " [ 5.41115830e-02 -7.60632552e-01]\n",
      " [-1.45347424e+00  1.29416313e+00]\n",
      " [ 3.66554121e-01  1.25281282e+00]\n",
      " [-2.90459990e+00  1.41572952e+00]\n",
      " [ 7.60308946e-01 -1.95829939e+00]\n",
      " [-7.45404855e-01  2.55995201e+00]\n",
      " [-1.70227705e-01  8.75141045e-01]\n",
      " [-8.41027509e-01 -9.85302387e-01]\n",
      " [ 8.30318026e-01  6.38352030e-01]\n",
      " [ 1.90768203e+00  2.68471510e-01]\n",
      " [-2.17510023e+00  2.31006023e-01]\n",
      " [ 2.22143285e-01  8.41110935e-01]\n",
      " [ 1.80984461e-01 -2.88341853e+00]\n",
      " [-1.82934419e+00 -6.68834876e-01]\n",
      " [ 1.82958192e+00 -3.25583644e-01]\n",
      " [-1.41584290e+00 -6.29532365e-01]\n",
      " [ 1.07213854e+00 -6.65306787e-01]\n",
      " [-8.98996701e-01  1.30841124e+00]\n",
      " [ 1.08222412e+00  8.88061390e-01]\n",
      " [ 1.14752890e+00  8.06004392e-01]\n",
      " [-9.50784951e-01 -7.99857190e-01]\n",
      " [-5.58909613e-02 -5.68055832e-01]\n",
      " [ 1.56422710e+00 -9.49973132e-01]\n",
      " [-7.21963194e-01  2.42572618e-01]\n",
      " [ 8.40127596e-01  2.56817853e+00]\n",
      " [-1.55229991e+00 -1.10400875e+00]\n",
      " [-9.64100143e-01  1.92350056e-01]\n",
      " [-2.94759364e-01  4.29196515e-01]\n",
      " [ 8.18132987e-01  2.89560855e-01]\n",
      " [-7.69261130e-02  2.25938942e+00]\n",
      " [ 5.76883593e-02 -1.79663455e+00]\n",
      " [ 3.78286483e+00  7.91177440e-01]\n",
      " [ 1.32368884e+00  1.12550154e+00]\n",
      " [-3.07258590e-01 -3.78055792e-01]\n",
      " [ 1.87503146e-02 -1.04552309e-01]\n",
      " [-1.58771132e-01  1.53914367e+00]\n",
      " [ 1.44622030e+00 -1.39604999e+00]\n",
      " [-1.96661733e+00 -2.00771641e+00]\n",
      " [ 5.02321081e-01 -1.31622719e+00]\n",
      " [-2.30849371e+00  1.38457785e+00]\n",
      " [ 7.57324992e-01  1.54157995e+00]\n",
      " [-2.43276909e-02 -8.66213099e-01]\n",
      " [-1.96556158e-01 -1.02749725e+00]\n",
      " [-2.34595159e-01 -1.53588060e+00]\n",
      " [ 1.67947830e+00 -1.55987580e+00]\n",
      " [ 7.16129136e-02 -2.28337756e-01]\n",
      " [-1.93620019e+00  1.89291274e+00]\n",
      " [-7.61069773e-01 -1.50290846e+00]\n",
      " [ 1.06608426e+00 -1.17564096e+00]\n",
      " [ 1.35799604e+00 -1.03779774e+00]\n",
      " [-8.57916284e-01  9.05946144e-02]\n",
      " [ 4.95591088e-01  2.91409847e+00]\n",
      " [ 4.35951880e-01 -6.18723340e-01]\n",
      " [-9.65248138e-01  2.35495344e-01]\n",
      " [ 5.27394149e-05  8.04124952e-01]\n",
      " [ 3.13972293e-01  3.29534352e-01]\n",
      " [-6.47854774e-01 -1.84443645e+00]\n",
      " [ 3.43265824e-01 -6.10049060e-01]\n",
      " [-1.30189900e+00 -5.80586601e-01]\n",
      " [ 9.27467372e-02 -8.31430622e-01]\n",
      " [ 2.65965149e-02 -1.86448736e+00]\n",
      " [ 1.12032806e-02  1.14662797e-01]\n",
      " [ 2.37423833e-01  1.44246290e+00]\n",
      " [-1.15281661e+00 -7.40949651e-01]\n",
      " [ 8.62084647e-02  2.01264756e-01]\n",
      " [-9.69024282e-01  8.73595074e-02]\n",
      " [ 5.32154427e-02  1.33906919e+00]\n",
      " [-6.15614890e-01  3.47878088e-02]\n",
      " [-5.90201403e-01 -2.96778015e-01]\n",
      " [ 1.35002315e+00 -1.75765865e+00]\n",
      " [ 2.48009565e+00  6.24219257e-02]\n",
      " [-1.01805395e-01  9.66621065e-01]\n",
      " [ 1.55129702e-01 -2.81432251e-02]\n",
      " [ 1.13908192e+00 -2.53668530e+00]\n",
      " [-4.12760533e-01  1.59931546e-01]\n",
      " [-1.43869935e+00 -2.47209979e+00]\n",
      " [-5.40134923e-01  8.62165562e-01]\n",
      " [ 4.57021093e-01  6.58091962e-01]\n",
      " [-2.47388679e+00 -1.52603756e+00]\n",
      " [ 1.08656225e+00 -2.77841050e-01]\n",
      " [-5.45623353e-01 -8.48871761e-01]\n",
      " [ 8.00274228e-01 -9.21260706e-01]\n",
      " [ 1.13890097e+00  3.57937313e-01]\n",
      " [-1.02176315e+00  1.01282606e+00]\n",
      " [-1.80875116e+00 -3.78813735e-01]\n",
      " [-6.05602266e-01  2.37471811e+00]\n",
      " [ 7.21350024e-01  9.14593002e-01]\n",
      " [ 1.52403135e+00  4.24976149e-01]\n",
      " [ 4.05861951e-01 -6.59857072e-01]\n",
      " [ 1.40461776e+00 -2.36355058e+00]\n",
      " [ 2.56124938e+00 -6.16945360e-01]\n",
      " [-1.18975439e+00 -1.25248908e-01]\n",
      " [-1.77584464e-01 -1.21280506e+00]\n",
      " [ 2.37801829e+00  4.79627538e-01]\n",
      " [ 7.51723095e-02 -1.64203870e+00]\n",
      " [ 2.51346228e-01 -7.81347765e-01]\n",
      " [ 1.55936725e-02 -2.35405559e-01]\n",
      " [-4.21764926e-01  9.73211848e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Given a dataset `X` with multiple features, standardize the dataset and then apply PCA to reduce its dimensionality to 2 principal components. Complete the missing parts of the code.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming X is defined \n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# MISSING CODE: Apply PCA to reduce X_scaled to 2 principal components\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ce813",
   "metadata": {},
   "source": [
    "### Question 15: Optimization Using Linear Algebra in Python\n",
    "**Describe how linear algebra can be used to solve optimization problems, particularly in the context of least squares for linear regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c6446",
   "metadata": {},
   "source": [
    "Linear algebra is fundamental in solving optimization problems, including those encountered in linear regression, particularly in the method of least squares. Here's how linear algebra can be applied for the following:\n",
    "\n",
    "1. **Problem Formulation**: Linear regression aims to find the best-fitting line or plane that minimizes the squared differences between observed and predicted values.\n",
    "\n",
    "2. **Matrix Representation**: We represent regression equations using matrices. The goal is to find coefficients that minimize the squared differences between observed and predicted values.\n",
    "\n",
    "3. **Solving the Problem**: Linear algebra helps us solve the optimization problem by manipulating matrices. We use techniques like matrix multiplication and inversion to find the coefficients efficiently.\n",
    "\n",
    "4. **Efficiency and Regularization**: Linear algebra allows for efficient computation of coefficients. In cases of overfitting, techniques like ridge regression modify the optimization problem, but linear algebra principles still apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e723eb3",
   "metadata": {},
   "source": [
    "\n",
    "### Question 16: Solving a Least Squares Problem for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1732916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [3. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Given matrices `X` (feature matrix) and `y` (target vector), solve the linear regression weights using the least squares solution. Complete the missing parts of the code.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])  # Feature matrix\n",
    "y = np.array([6, 8, 9, 11])  # Target vector\n",
    "\n",
    "# Add a column of ones to X for the intercept\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# MISSING CODE: Solve for the weights using the least squares solution (X^T X)^{-1} X^T y\n",
    "weights = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(f\"Weights: {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d3226",
   "metadata": {},
   "source": [
    "- `np.linalg.pinv(X)` will compute the pseudo-inverse of the feature matrix \\( X \\).\n",
    "- The pseudo-inverse \\( (X^T X)^{-1} X^T \\) effectively will calculate the least squares solution.\n",
    "- `np.linalg.pinv(X) @ y` will perform matrix multiplication to obtain the weights.\n",
    "- The resulting `weights` variable will contain the weights for the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c90a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [3. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Using np.linalg.pinv(X)\n",
    "weights = np.linalg.pinv(X) @ y\n",
    "print(f\"Weights: {weights}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
